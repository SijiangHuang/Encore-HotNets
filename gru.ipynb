{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, Tensor\n",
    "from typing import List\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from utils.dataset import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "pairs = 8192*2\n",
    "pairdata, freqpairs, n_size, n_interval = get_fb_data(pairs)\n",
    "sizedata = get_data(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_set = defaultdict(list)\n",
    "target_set = defaultdict(list)\n",
    "size_set = {}\n",
    "seq_len = 16\n",
    "\n",
    "for pair in range(pairs):\n",
    "    size_index = pairdata[freqpairs[pair]].size_index.values\n",
    "    target_index = np.concatenate((size_index[1:], size_index[0:1]))\n",
    "    for i in range(len(size_index) - seq_len):\n",
    "        seq_set[pair].append(size_index[i:i+seq_len])\n",
    "        target_set[pair].append(target_index[i:i+seq_len])\n",
    "        size_set[pair] = sizedata[pair]\n",
    "    seq_set[pair] = np.array(seq_set[pair])\n",
    "    target_set[pair] = np.array(target_set[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(seed, batch=32):\n",
    "    np.random.seed(seed)\n",
    "    dataset = []\n",
    "    ps = [np.random.randint(pairs) for i in range(batch)]\n",
    "    for pair in ps:\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size_set[pair], target_set[pair][ran_index]])\n",
    "    return dataset\n",
    "\n",
    "def inputTensor(lines):\n",
    "    tensor = torch.zeros(lines.shape[1], lines.shape[0], n_size, dtype=torch.long)\n",
    "    for line in range(lines.shape[0]):\n",
    "        for i in range(lines.shape[1]):\n",
    "            size = lines[line][i]\n",
    "            tensor[i][line][size] = 1\n",
    "    return tensor\n",
    "\n",
    "dataset = sample_dataset(0)\n",
    "dataloader = DataLoader(dataset[:32], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeToHidden(nn.Module):\n",
    "    def __init__(self, input_size,  n_deep, hidden_size, n_layer):\n",
    "        super(SizeToHidden, self).__init__()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_net = nn.Sequential(\n",
    "                    nn.Linear(input_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "        for _ in range(n_deep):\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(hidden_size))\n",
    "            )\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, out_features=hidden_size * n_layer)\n",
    "\n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        x = self.in_net(x)\n",
    "        i = 0\n",
    "        for lin in self.lins:\n",
    "            if i % 3 == 0:\n",
    "                x_ = x\n",
    "            x = lin(x)\n",
    "            if i % 3 == 1:\n",
    "                x = x + x_\n",
    "            i = (i+1)%3\n",
    "        x = self.output(x)\n",
    "        x = x.view(-1, self.n_layer, self.hidden_size)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        # x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layer, n_deep):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layer)\n",
    "        \n",
    "        self.o2o = nn.Linear(hidden_size+n_size, hidden_size)\n",
    "        self.ots = nn.ModuleList()\n",
    "        for _ in range(n_deep):\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            # self.ots.append(\n",
    "            #     nn.Sequential(\n",
    "            #         nn.LayerNorm(hidden_size))\n",
    "            # )\n",
    "        self.h2o = nn.Linear(hidden_size, n_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.norm_1 = nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        out = self.norm(out)\n",
    "        i=0\n",
    "        for o in self.ots:\n",
    "            if i%2==0:\n",
    "                out_=out\n",
    "            out = o(out)\n",
    "            if i%2==1:\n",
    "                out = out + out_\n",
    "            i = (i+1)%2\n",
    "        out = self.norm_1(out)\n",
    "        out = self.h2o(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "gru = GRU(n_size, hidden_size, 4, 48).to(device)\n",
    "s2h = SizeToHidden(n_size, 2, hidden_size, 4).to(device)\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8e5,16e5,24e5,32e5],gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size = 128\n",
    "# gru = GRU(n_size, hidden_size, 1).to(device)\n",
    "# s2h = SizeToHidden(n_size, [64, 128], hidden_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31073822, 2120192, 33194014)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total parameters and trainable parameters of gru and s2h\n",
    "def get_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "get_params(gru)[0], get_params(s2h)[0], get_params(gru)[0] + get_params(s2h)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5157940"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_flow = 0\n",
    "for i in range(pairs):\n",
    "    sum_flow += len(pairdata[freqpairs[i]])\n",
    "sum_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.882237777777775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_params(gru)[0] + get_params(s2h)[0]) / 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = 'final'\n",
    "# gru = torch.load('model/{date}/gru.pth'.format(date=date))\n",
    "# s2h = torch.load('model/{date}/s2h.pth'.format(date=date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097003 1097002\n"
     ]
    }
   ],
   "source": [
    "gru=torch.load('model/gru-09201.pth')\n",
    "s2h=torch.load('model/s2h-09201.pth')\n",
    "save_dict = torch.load(\"model/save_dict-09201.pth\")\n",
    "optimizer.load_state_dict(save_dict['optimizer'])\n",
    "scheduler._step_count = save_dict[\"_step_count\"]\n",
    "scheduler.last_epoch = save_dict[\"last_epoch\"]\n",
    "print(save_dict[\"_step_count\"],save_dict[\"last_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer):\n",
    "    gru.train()\n",
    "    s2h.train()\n",
    "    sum_loss = 0\n",
    "    for seq_tensor, size_tensor, target_tensor in dataloader:\n",
    "        seq_tensor = inputTensor(seq_tensor).float().to(device)\n",
    "        size_tensor = size_tensor.float().to(device)\n",
    "        target_tensor = target_tensor.T.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, hn = gru(seq_tensor, s2h(size_tensor))\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            loss += nn.NLLLoss()(output[i], target_tensor[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss.item() / seq_tensor.shape[0] * seq_tensor.shape[1]\n",
    "    return sum_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总参数数量和：31073822\n",
      "总参数数量和：2120192\n",
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = gru\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "model = s2h\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "print(optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.8130968809127808 0.8145476836562157 1098004 [1e-05, 1e-05] 28.57780408859253\n",
      "2000 0.8130972981452942 0.8126182305216789 1099004 [1e-05, 1e-05] 58.50086212158203\n",
      "3000 0.9203750491142273 0.8111932932138443 1100004 [1e-05, 1e-05] 88.08485960960388\n",
      "4000 0.8036040663719177 0.8132229589819908 1101004 [1e-05, 1e-05] 116.02132511138916\n",
      "5000 0.8083335161209106 0.8134597735404968 1102004 [1e-05, 1e-05] 145.85380864143372\n",
      "6000 0.8000327944755554 0.8126526020169258 1103004 [1e-05, 1e-05] 175.75295162200928\n",
      "7000 0.7912278175354004 0.810493416249752 1104004 [1e-05, 1e-05] 205.66873121261597\n",
      "8000 0.7876191139221191 0.8120693516135216 1105004 [1e-05, 1e-05] 235.5534119606018\n",
      "9000 0.8335492014884949 0.8106525501608849 1106004 [1e-05, 1e-05] 265.68156242370605\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dataset \u001b[39m=\u001b[39m sample_dataset(i,batch\u001b[39m=\u001b[39mbatch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset[:], batch_size\u001b[39m=\u001b[39mbatch, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m train(dataloader, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()    \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m sum_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m seq_tensor, size_tensor, target_tensor \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     seq_tensor \u001b[39m=\u001b[39m inputTensor(seq_tensor)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     size_tensor \u001b[39m=\u001b[39m size_tensor\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     target_tensor \u001b[39m=\u001b[39m target_tensor\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(lines\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         size \u001b[39m=\u001b[39m lines[line][i]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         tensor[i][line][size] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lr = 5e-4\n",
    "# optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr)\n",
    "batch=64\n",
    "s_time = time.time()\n",
    "plot_every = 1000\n",
    "avg_loss = 0\n",
    "for i in range(1000001):\n",
    "    dataset = sample_dataset(i,batch=batch)\n",
    "    dataloader = DataLoader(dataset[:], batch_size=batch, shuffle=True)\n",
    "    loss = train(dataloader, optimizer)\n",
    "    scheduler.step()    \n",
    "    avg_loss += loss\n",
    "    if i and i % plot_every == 0:\n",
    "        print(i, loss, avg_loss / plot_every, scheduler._step_count, scheduler.get_last_lr(),time.time() - s_time)\n",
    "        torch.save(gru, 'model/gru-09201.pth')\n",
    "        torch.save(s2h, 'model/s2h-09201.pth')\n",
    "        save_dict = {'epoch':i,\"optimizer\":optimizer.state_dict(),\"_step_count\":scheduler._step_count,\"last_epoch\":scheduler.last_epoch}\n",
    "        torch.save(save_dict,\"model/save_dict-09201.pth\")\n",
    "        if avg_loss / plot_every < 0.18:\n",
    "            print(i, avg_loss / plot_every)\n",
    "            break\n",
    "        avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2).to(device)\n",
    "def sample(size_data, seq_length, start_size=8):\n",
    "    gru.eval()\n",
    "    s2h.eval()\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        size_tensor = torch.tensor(size_data, dtype=torch.float).to(device)\n",
    "        hn = s2h(size_tensor)\n",
    "        output_seq = [start_size]\n",
    "        size = start_size\n",
    "        for _ in range(seq_length - 1):\n",
    "            input = inputTensor(np.array([[size]])).to(device)\n",
    "            input = input.float()\n",
    "            output, hn = gru(input, hn)\n",
    "            output = softmax(output)\n",
    "            p_size = output.detach().cpu().numpy().squeeze()\n",
    "            size = np.random.choice(n_size, p=p_size)\n",
    "            output_seq.append(size)\n",
    "        return output_seq\n",
    "\n",
    "def is_subarray(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "    for i in range(len(arr1) - len(arr2) + 1):\n",
    "        if np.array_equal(arr1[i:i+len(arr2)], arr2):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 0\n",
    "start_size = 8\n",
    "for i in range(100):\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "    a = sample(sizedata[pair], 16, start_size)\n",
    "    print(a, is_subarray(size_index, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "s2s_pair, size_trans = get_trans(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plf_dict={}\n",
    "# print(size_trans[0])\n",
    "# plf_dict[str(sizedata[0])]=size_trans[0]\n",
    "\n",
    "# print(sizedata[0])\n",
    "minp=100\n",
    "maxp=0\n",
    "ans=0\n",
    "for i in range(1000):\n",
    "    for j in range(i):\n",
    "        if i==j:\n",
    "            continue\n",
    "        minp=min(np.sum(np.abs(sizedata[i]-sizedata[j])),minp)\n",
    "        maxp=max(maxp,np.sum(np.abs(sizedata[i]-sizedata[j])))\n",
    "        if(np.sum(np.square(sizedata[i]-sizedata[j]))<0.001):\n",
    "            ans+=1\n",
    "print(maxp,minp,ans)\n",
    "# for i in range(1000):\n",
    "#     try:\n",
    "#         plf_dict[str(sizedata[i])]\n",
    "#     # if sizedata[i] in plf_dict.keys():\n",
    "#         temp = plf_dict[str(sizedata[i])]\n",
    "#         temp += size_trans[i]\n",
    "#         temp/=2\n",
    "#         plf_dict[str(sizedata[i])]=temp\n",
    "#         print(\"1\\n\")\n",
    "#     except:\n",
    "#         plf_dict[str(sizedata[i])]=size_trans[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "encore_seq = np.zeros((pairs, 1000))\n",
    "he_seq = np.zeros((pairs, 1000))\n",
    "\n",
    "for pair in tqdm(range(pairs)):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    size_seq = []\n",
    "    while len(size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq.append(size)\n",
    "    size_seq = np.array(size_seq)[0:1000]\n",
    "    he_seq[pair] = size_seq\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq = [start_size]\n",
    "        while len(size_seq) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq += list(new_size[:])\n",
    "                # start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "            start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        \n",
    "        \n",
    "        size_seq = np.array(size_seq)\n",
    "        values, counts = np.unique(size_seq, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq[:-1] * n_size + size_seq[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            # print(pair, seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "            break\n",
    "\n",
    "    encore_seq[pair] = size_seq[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = pairdata[freqpairs[pair]]['size_index'].values\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        grams[i][pair][values] = counts\n",
    "    grams[i] /= grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "he_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    he_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = he_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        he_grams[i][pair][values] = counts\n",
    "    he_grams[i] /= he_grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "encore_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    encore_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = encore_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        encore_grams[i][pair][values] = counts\n",
    "    encore_grams[i] /= encore_grams[i].sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_jsds, encore_jsds = {}, {}\n",
    "for i in range(2, 5):\n",
    "    he_jsds[i] = []    \n",
    "    encore_jsds[i] = []    \n",
    "    for pair in range(pairs):\n",
    "        he_jsds[i].append(JSD(grams[i][pair], he_grams[i][pair]))\n",
    "        encore_jsds[i].append(JSD(grams[i][pair], encore_grams[i][pair]))\n",
    "    he_jsds[i] = np.array(he_jsds[i])\n",
    "    encore_jsds[i] = np.array(encore_jsds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(2, 5):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.subplots_adjust(left=0.18, top=0.95, bottom=0.24, right=0.98)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    values, bins = np.histogram(encore_jsds[i], bins=np.arange(0, np.max(encore_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='CornFlowerBlue', label='Encore-Sequential')\n",
    "    values, bins = np.histogram(he_jsds[i], bins=np.arange(0, np.max(he_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='IndianRed', label='Common Practice')\n",
    "    plt.ylim(0, 1.05)\n",
    "    # plt.legend(fontsize=20, frameon=False, loc=(0.45, 0.2))\n",
    "    plt.ylabel('CDF', fontsize=20)\n",
    "    plt.xlabel('JSD', fontsize=20)\n",
    "    plt.grid(linestyle='-.')\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    if i == 2:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.125, 0.84, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    elif i == 3:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.22, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    else:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.3, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    plt.legend(fontsize=20, frameon=False, loc=(0.185, -0.025), handletextpad=0.5)\n",
    "\n",
    "    plt.savefig('figure/{i}-gram-jsd.pdf'.format(i=i), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.002845626767000088 0.04350682213516826 0.0736751094920089\n",
      "1 0.0032875506585200343 0.07589432706204512 0.1042314247342685\n",
      "2 0.011619882504388866 0.0728808903307351 0.09232638777799812\n",
      "3 0.013737479924051079 0.06777110048255232 0.0773797892778813\n",
      "4 0.007186956156707693 0.07908471434388073 0.12228350243216352\n",
      "5 0.023064866238335986 0.059741297080408165 0.05843249684209055\n",
      "6 0.004376923380525691 0.08416785729521668 0.12312332078551216\n",
      "7 0.004448849655145703 0.07089777510479905 0.11284068059687372\n",
      "8 0.0038753809372614146 0.08352678212687983 0.11672103015604808\n",
      "9 0.011053668170946775 0.07665172406568428 0.09226857847679462\n",
      "10 0.004382468517019655 0.05964339482044021 0.09568657866273808\n",
      "11 0.009716078706594761 0.09459833981521493 0.12403968853068947\n",
      "12 0.003250738097333056 0.05924415727974259 0.09530537767837935\n",
      "13 0.004327691022793386 0.05345211696883908 0.1098784278877494\n",
      "14 0.00634525842023049 0.06024911171951057 0.09999558257104302\n",
      "15 0.004739407951800096 0.07615467232473175 0.09651893234206828\n",
      "16 0.00492775310016688 0.04611236801590178 0.08837843908881851\n",
      "17 0.004690293638181804 0.08173150683031868 0.1338076640505814\n",
      "18 0.006844140337111579 0.07457590699546923 0.09396542944009642\n",
      "19 0.011286591435321049 0.06889994938907956 0.1010157209610235\n",
      "20 0.0038557453618802036 0.06659394022455672 0.11493331334406842\n",
      "21 0.010481376407305123 0.06990348584901987 0.10026866857609482\n",
      "22 0.008971318626272411 0.07934732767569334 0.0912383806024383\n",
      "23 0.0036934061431003837 0.07089947307683939 0.12231092211836225\n",
      "24 0.008083755213525019 0.06641600583829274 0.10104962363428827\n",
      "25 0.008052840788730305 0.07681827709387075 0.12682986798650778\n",
      "26 0.004720985470720458 0.05796328156806434 0.08419552332296416\n",
      "27 0.006228236285584271 0.050915825670789616 0.06931240452758751\n",
      "28 0.003923755440108905 0.0781817131003104 0.10568594630988733\n",
      "29 0.0040643520170661135 0.08011962872892275 0.1178340121193695\n",
      "30 0.004841437085781591 0.05944617152780713 0.08280698660367523\n",
      "31 0.004645168692930653 0.037707002909015214 0.04271960550741439\n",
      "32 0.012474670309007594 0.09126638726395819 0.10461376791490962\n",
      "33 0.0037350967540331044 0.0657528518232936 0.09210750492251432\n",
      "34 0.010457421485820082 0.059754468423807924 0.10940742116628674\n",
      "35 0.013269613418174895 0.05981447263839785 0.08351573042379531\n",
      "36 0.007322638234100362 0.06353364758375463 0.10451082864691\n",
      "37 0.004053940417780806 0.06795455032475953 0.08587515511754218\n",
      "38 0.009202056952878656 0.054238861157543936 0.07054838917657212\n",
      "39 0.0032267179745263906 0.07832831087398658 0.11519057774560024\n",
      "40 0.0074632027488673374 0.0777952130004182 0.10117835158983615\n",
      "41 0.004593584767159353 0.06301300110888668 0.0898293496828995\n",
      "42 0.010262912894997898 0.06783462448041944 0.08580279601879086\n",
      "43 0.004864869350137325 0.08586404371914251 0.09460264242519983\n",
      "44 0.004013826164970076 0.0610945478933213 0.09899487617170973\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m size_seq_gen \u001b[39m=\u001b[39m [start_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(size_seq_gen) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     new_size \u001b[39m=\u001b[39m sample(size_data, seq_len, start_size\u001b[39m=\u001b[39;49mstart_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     size_seq_gen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(new_size[\u001b[39m1\u001b[39m:])\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m inputTensor(np\u001b[39m.\u001b[39marray([[size]]))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output, hn \u001b[39m=\u001b[39m gru(\u001b[39minput\u001b[39;49m, hn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m softmax(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m p_size \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m2\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     out_\u001b[39m=\u001b[39mout\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m out \u001b[39m=\u001b[39m o(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m2\u001b[39m\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m out_\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_jsds, he_jsds,min_jsds = [], [],[]\n",
    "for pair in range(500):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = [start_size]\n",
    "        while len(size_seq_gen) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq_gen += list(new_size[1:])\n",
    "            start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "                #     start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = np.array(size_seq_gen)\n",
    "        values, counts = np.unique(size_seq_gen, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        # print(seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            break\n",
    "\n",
    "    rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "    values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "    rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "    rnn_s2s_pair[values] = counts\n",
    "    rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "\n",
    "    he_size_seq = []\n",
    "    while len(he_size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        he_size_seq.append(size)\n",
    "    he_size_seq = np.array(he_size_seq)\n",
    "\n",
    "    he_s2s_pair = [he_size_seq[:-1] * n_size + he_size_seq[1:]]  \n",
    "    values, counts = np.unique(he_s2s_pair, return_counts=True)\n",
    "    he_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    he_s2s_pair[values] = counts\n",
    "    he_s2s_pair /= he_s2s_pair.sum()\n",
    "    \n",
    "    min_size_seq = []\n",
    "    min_size_seq.append(np.random.choice(n_size, p=size_data))\n",
    "    while len(min_size_seq) < 1000:\n",
    "        min_size_seq.append(np.random.choice(n_size, p=size_trans[pair][min_size_seq[-1]]))\n",
    "    min_size_seq = np.array(min_size_seq)\n",
    "        \n",
    "    min_s2s_pair = [min_size_seq[:-1] * n_size + min_size_seq[1:]]  \n",
    "    values, counts = np.unique(min_s2s_pair, return_counts=True)\n",
    "    min_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    min_s2s_pair[values] = counts\n",
    "    min_s2s_pair /= min_s2s_pair.sum()\n",
    "\n",
    "    print(pair, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]), JSD(he_s2s_pair, s2s_pair[pair]))\n",
    "    rnn_jsds.append(JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "    min_jsds.append(JSD(min_s2s_pair, s2s_pair[pair]))\n",
    "    he_jsds.append(JSD(he_s2s_pair, s2s_pair[pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values, bins = np.histogram(rnn_jsds, bins=np.arange(0, np.max(rnn_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(he_jsds, bins=np.arange(0, np.max(he_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(min_jsds, bins=np.arange(0, np.max(min_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "plt.ylim(0, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(gru, 'models/gru-0504.pth')\n",
    "# torch.save(s2h, 'models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeDecoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dims, latent_dim):\n",
    "        super(SizeDecoder, self).__init__()\n",
    "        self.decoder = torch.nn.ModuleList()\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_dim, out_features=h_dim,),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            in_dim = h_dim\n",
    "        self.output = nn.Linear(hidden_dims[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        for module in self.decoder:\n",
    "            x = module(x)\n",
    "        result = self.output(x)\n",
    "        result = F.softmax(result, dim=1)\n",
    "        return result\n",
    "    \n",
    "decoder = torch.load('models/size-decoder-0425.pth')\n",
    "gru = torch.load('models/gru-0504.pth')\n",
    "s2h = torch.load('models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "def sample_noisy_dataset(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = []\n",
    "    for i in tqdm(range(n)):\n",
    "        latent_dim = 32\n",
    "        z = torch.randn((1, latent_dim)).to(device)\n",
    "        size = decoder(z)\n",
    "        size = size.squeeze().detach().to('cpu').numpy()\n",
    "        size[size < 1e-3] = 0\n",
    "        size /= size.sum()\n",
    "\n",
    "        dis = []\n",
    "        for j in range(1000):\n",
    "            loss = JSD(size, sizedata[j])\n",
    "            dis.append(loss)\n",
    "\n",
    "        pair = np.argmin(dis)\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size, target_set[pair][ran_index]])\n",
    "        \n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
