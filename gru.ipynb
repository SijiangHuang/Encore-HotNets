{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, Tensor\n",
    "from typing import List\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from utils.dataset import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "pairs = 8192*2\n",
    "pairdata, freqpairs, n_size, n_interval = get_fb_data(pairs)\n",
    "sizedata = get_data(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_set = defaultdict(list)\n",
    "target_set = defaultdict(list)\n",
    "size_set = {}\n",
    "seq_len = 16\n",
    "\n",
    "for pair in range(pairs):\n",
    "    size_index = pairdata[freqpairs[pair]].size_index.values\n",
    "    target_index = np.concatenate((size_index[1:], size_index[0:1]))\n",
    "    for i in range(len(size_index) - seq_len):\n",
    "        seq_set[pair].append(size_index[i:i+seq_len])\n",
    "        target_set[pair].append(target_index[i:i+seq_len])\n",
    "        size_set[pair] = sizedata[pair]\n",
    "    seq_set[pair] = np.array(seq_set[pair])\n",
    "    target_set[pair] = np.array(target_set[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(seed, batch=32):\n",
    "    np.random.seed(seed)\n",
    "    dataset = []\n",
    "    ps = [np.random.randint(pairs) for i in range(batch)]\n",
    "    for pair in ps:\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size_set[pair], target_set[pair][ran_index]])\n",
    "    return dataset\n",
    "\n",
    "def inputTensor(lines):\n",
    "    tensor = torch.zeros(lines.shape[1], lines.shape[0], n_size, dtype=torch.long)\n",
    "    for line in range(lines.shape[0]):\n",
    "        for i in range(lines.shape[1]):\n",
    "            size = lines[line][i]\n",
    "            tensor[i][line][size] = 1\n",
    "    return tensor\n",
    "\n",
    "dataset = sample_dataset(0)\n",
    "dataloader = DataLoader(dataset[:32], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeToHidden(nn.Module):\n",
    "    def __init__(self, input_size,  n_deep, hidden_size, n_layer):\n",
    "        super(SizeToHidden, self).__init__()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_net = nn.Sequential(\n",
    "                    nn.Linear(input_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "        for _ in range(n_deep):\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(hidden_size))\n",
    "            )\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, out_features=hidden_size * n_layer)\n",
    "\n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        x = self.in_net(x)\n",
    "        i = 0\n",
    "        for lin in self.lins:\n",
    "            if i % 3 == 0:\n",
    "                x_ = x\n",
    "            x = lin(x)\n",
    "            if i % 3 == 1:\n",
    "                x = x + x_\n",
    "            i = (i+1)%3\n",
    "        x = self.output(x)\n",
    "        x = x.view(-1, self.n_layer, self.hidden_size)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        # x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layer, n_deep):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layer)\n",
    "        \n",
    "        self.o2o = nn.Linear(hidden_size+n_size, hidden_size)\n",
    "        self.ots = nn.ModuleList()\n",
    "        for _ in range(n_deep):\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            # self.ots.append(\n",
    "            #     nn.Sequential(\n",
    "            #         nn.LayerNorm(hidden_size))\n",
    "            # )\n",
    "        self.h2o = nn.Linear(hidden_size, n_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.norm_1 = nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        out = self.norm(out)\n",
    "        i=0\n",
    "        for o in self.ots:\n",
    "            if i%2==0:\n",
    "                out_=out\n",
    "            out = o(out)\n",
    "            if i%2==1:\n",
    "                out = out + out_\n",
    "            i = (i+1)%2\n",
    "        out = self.norm_1(out)\n",
    "        out = self.h2o(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "gru = GRU(n_size, hidden_size, 4, 48).to(device)\n",
    "s2h = SizeToHidden(n_size, 2, hidden_size, 4).to(device)\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8e5,16e5,24e5,32e5],gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size = 128\n",
    "# gru = GRU(n_size, hidden_size, 1).to(device)\n",
    "# s2h = SizeToHidden(n_size, [64, 128], hidden_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31073822, 2120192, 33194014)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total parameters and trainable parameters of gru and s2h\n",
    "def get_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "get_params(gru)[0], get_params(s2h)[0], get_params(gru)[0] + get_params(s2h)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5157940"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_flow = 0\n",
    "for i in range(pairs):\n",
    "    sum_flow += len(pairdata[freqpairs[i]])\n",
    "sum_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.882237777777775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_params(gru)[0] + get_params(s2h)[0]) / 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = 'final'\n",
    "# gru = torch.load('model/{date}/gru.pth'.format(date=date))\n",
    "# s2h = torch.load('model/{date}/s2h.pth'.format(date=date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru=torch.load('model/gru-09201.pth')\n",
    "s2h=torch.load('model/s2h-09201.pth')\n",
    "save_dict = torch.load(\"model/save_dict-09201.pth\")\n",
    "optimizer.load_state_dict(save_dict['optimizer'])\n",
    "scheduler._step_count = save_dict[\"_step_count\"]\n",
    "scheduler.last_epoch = save_dict[\"last_epoch\"]\n",
    "print(save_dict[\"_step_count\"],save_dict[\"last_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer):\n",
    "    gru.train()\n",
    "    s2h.train()\n",
    "    sum_loss = 0\n",
    "    for seq_tensor, size_tensor, target_tensor in dataloader:\n",
    "        seq_tensor = inputTensor(seq_tensor).float().to(device)\n",
    "        size_tensor = size_tensor.float().to(device)\n",
    "        target_tensor = target_tensor.T.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, hn = gru(seq_tensor, s2h(size_tensor))\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            loss += nn.NLLLoss()(output[i], target_tensor[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss.item() / seq_tensor.shape[0] * seq_tensor.shape[1]\n",
    "    return sum_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总参数数量和：31073822\n",
      "总参数数量和：2120192\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = gru\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "model = s2h\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "print(optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2.3197829723358154 2.356151619434357 1002 [0.0001, 0.0001] 38.30011439323425\n",
      "2000 2.269982099533081 2.316327381134033 2002 [0.0001, 0.0001] 76.02425265312195\n",
      "3000 2.3075168132781982 2.3105399470329284 3002 [0.0001, 0.0001] 115.8005781173706\n",
      "4000 2.339743137359619 2.306196941614151 4002 [0.0001, 0.0001] 155.5390362739563\n",
      "5000 2.2670974731445312 2.304141454458237 5002 [0.0001, 0.0001] 195.47496843338013\n",
      "6000 2.282714366912842 2.3019437508583067 6002 [0.0001, 0.0001] 235.46065711975098\n",
      "7000 2.290595054626465 2.3029810271263123 7002 [0.0001, 0.0001] 274.27069211006165\n",
      "8000 2.3033504486083984 2.299550670623779 8002 [0.0001, 0.0001] 313.89147663116455\n",
      "9000 2.3358852863311768 2.2992681300640108 9002 [0.0001, 0.0001] 353.8721582889557\n",
      "10000 2.256924867630005 2.2974956772327424 10002 [0.0001, 0.0001] 393.69573497772217\n",
      "11000 2.265164375305176 2.295911640405655 11002 [0.0001, 0.0001] 433.5510666370392\n",
      "12000 2.33732008934021 2.2980557754039763 12002 [0.0001, 0.0001] 471.9931881427765\n",
      "13000 2.2686877250671387 2.2958231484889984 13002 [0.0001, 0.0001] 511.7843792438507\n",
      "14000 2.302356719970703 2.295377010345459 14002 [0.0001, 0.0001] 551.4116082191467\n",
      "15000 2.2833847999572754 2.294939829111099 15002 [0.0001, 0.0001] 591.5285844802856\n",
      "16000 2.3117334842681885 2.295370145559311 16002 [0.0001, 0.0001] 631.2192571163177\n",
      "17000 2.3199572563171387 2.293109505176544 17002 [0.0001, 0.0001] 669.8350446224213\n",
      "18000 2.2984604835510254 2.2935435559749604 18002 [0.0001, 0.0001] 708.1667680740356\n",
      "19000 2.322932243347168 2.2915047852993013 19002 [0.0001, 0.0001] 747.0962247848511\n",
      "20000 2.2782506942749023 2.2925554695129393 20002 [0.0001, 0.0001] 786.4109952449799\n",
      "21000 2.2901432514190674 2.291470363378525 21002 [0.0001, 0.0001] 826.1268692016602\n",
      "22000 2.3334779739379883 2.2929703347682953 22002 [0.0001, 0.0001] 865.0397338867188\n",
      "23000 2.2838451862335205 2.2936315793991087 23002 [0.0001, 0.0001] 903.9643847942352\n",
      "24000 2.263273000717163 2.2911982953548433 24002 [0.0001, 0.0001] 943.6513345241547\n",
      "25000 2.3200998306274414 2.2929929599761962 25002 [0.0001, 0.0001] 983.2562375068665\n",
      "26000 2.3405258655548096 2.2934148433208468 26002 [0.0001, 0.0001] 1021.8526146411896\n",
      "27000 2.334256649017334 2.2920036568641664 27002 [0.0001, 0.0001] 1060.907562494278\n",
      "28000 2.2530057430267334 2.291047763109207 28002 [0.0001, 0.0001] 1100.8197267055511\n",
      "29000 2.3274312019348145 2.2922492678165436 29002 [0.0001, 0.0001] 1140.342824935913\n",
      "30000 2.3145408630371094 2.291044190168381 30002 [0.0001, 0.0001] 1180.3104209899902\n",
      "31000 2.3099842071533203 2.2913850824832918 31002 [0.0001, 0.0001] 1220.2959172725677\n",
      "32000 2.287757635116577 2.2901028990745544 32002 [0.0001, 0.0001] 1259.7352757453918\n",
      "33000 2.331862211227417 2.290191389799118 33002 [0.0001, 0.0001] 1298.897476196289\n",
      "34000 2.2320175170898438 2.290398179769516 34002 [0.0001, 0.0001] 1338.1604962348938\n",
      "35000 2.316326141357422 2.2912674543857574 35002 [0.0001, 0.0001] 1377.8470244407654\n",
      "36000 2.3366000652313232 2.290006751537323 36002 [0.0001, 0.0001] 1417.2705125808716\n",
      "37000 2.2667734622955322 2.290820990085602 37002 [0.0001, 0.0001] 1456.7165343761444\n",
      "38000 2.270066738128662 2.291157068967819 38002 [0.0001, 0.0001] 1496.1916062831879\n",
      "39000 2.276423454284668 2.291390337944031 39002 [0.0001, 0.0001] 1535.5957431793213\n",
      "40000 2.306502342224121 2.290503442287445 40002 [0.0001, 0.0001] 1574.7742929458618\n",
      "41000 2.2652859687805176 2.289701668262482 41002 [0.0001, 0.0001] 1614.6114795207977\n",
      "42000 2.275559902191162 2.289464275598526 42002 [0.0001, 0.0001] 1654.456012248993\n",
      "43000 2.295710802078247 2.2883574662208557 43002 [0.0001, 0.0001] 1694.2994282245636\n",
      "44000 2.3065106868743896 2.2898531606197357 44002 [0.0001, 0.0001] 1734.1670126914978\n",
      "45000 2.3120410442352295 2.2899554147720336 45002 [0.0001, 0.0001] 1773.729420185089\n",
      "46000 2.287518262863159 2.292168489933014 46002 [0.0001, 0.0001] 1813.2988193035126\n",
      "47000 2.29441499710083 2.289374739408493 47002 [0.0001, 0.0001] 1853.400344133377\n",
      "48000 2.3052709102630615 2.290269356966019 48002 [0.0001, 0.0001] 1893.363690853119\n",
      "49000 2.3154349327087402 2.291235142946243 49002 [0.0001, 0.0001] 1933.1916873455048\n",
      "50000 2.301717519760132 2.2905352420806886 50002 [0.0001, 0.0001] 1973.0471243858337\n",
      "51000 2.3346214294433594 2.2904349009990694 51002 [0.0001, 0.0001] 2011.909280538559\n",
      "52000 2.3103983402252197 2.290966586112976 52002 [0.0001, 0.0001] 2050.8510975837708\n",
      "53000 2.2928307056427 2.2901475927829744 53002 [0.0001, 0.0001] 2089.6208913326263\n",
      "54000 2.239565849304199 2.2880117297172546 54002 [0.0001, 0.0001] 2128.167731285095\n",
      "55000 2.3033628463745117 2.2883796529769898 55002 [0.0001, 0.0001] 2165.358677148819\n",
      "56000 2.293778896331787 2.2890536732673645 56002 [0.0001, 0.0001] 2203.6398515701294\n",
      "57000 2.28956937789917 2.2881431243419645 57002 [0.0001, 0.0001] 2243.3802421092987\n",
      "58000 2.3070993423461914 2.2877130925655367 58002 [0.0001, 0.0001] 2282.340240240097\n",
      "59000 2.239492416381836 2.2880017144680025 59002 [0.0001, 0.0001] 2322.1744158267975\n",
      "60000 2.3186404705047607 2.2885824592113493 60002 [0.0001, 0.0001] 2361.8663437366486\n",
      "61000 2.3092715740203857 2.2877820575237275 61002 [0.0001, 0.0001] 2401.6122035980225\n",
      "62000 2.2545688152313232 2.287740751743317 62002 [0.0001, 0.0001] 2440.4794631004333\n",
      "63000 2.288132667541504 2.2872913858890533 63002 [0.0001, 0.0001] 2480.506914615631\n",
      "64000 2.274998188018799 2.289386645555496 64002 [0.0001, 0.0001] 2520.4364247322083\n",
      "65000 2.294412612915039 2.286846756696701 65002 [0.0001, 0.0001] 2560.13191986084\n",
      "66000 2.2746059894561768 2.287420870542526 66002 [0.0001, 0.0001] 2599.65193772316\n",
      "67000 2.262253522872925 2.2873102152347564 67002 [0.0001, 0.0001] 2639.5259294509888\n",
      "68000 2.300908327102661 2.2880816950798035 68002 [0.0001, 0.0001] 2675.709202528\n",
      "69000 2.269874095916748 2.2879053082466125 69002 [0.0001, 0.0001] 2712.050083875656\n",
      "70000 2.282244920730591 2.2867995193004607 70002 [0.0001, 0.0001] 2751.876296520233\n",
      "71000 2.2828853130340576 2.286650109052658 71002 [0.0001, 0.0001] 2791.743026971817\n",
      "72000 2.303302526473999 2.288329688549042 72002 [0.0001, 0.0001] 2831.79470038414\n",
      "73000 2.2724814414978027 2.286748844385147 73002 [0.0001, 0.0001] 2871.678690433502\n",
      "74000 2.262561798095703 2.287152889251709 74002 [0.0001, 0.0001] 2910.5193235874176\n",
      "75000 2.3306026458740234 2.286029570102692 75002 [0.0001, 0.0001] 2950.363268136978\n",
      "76000 2.2123308181762695 2.285564280748367 76002 [0.0001, 0.0001] 2990.3033318519592\n",
      "77000 2.270242214202881 2.2856114192008974 77002 [0.0001, 0.0001] 3029.9903342723846\n",
      "78000 2.2604622840881348 2.2860580282211305 78002 [0.0001, 0.0001] 3069.4079535007477\n",
      "79000 2.2608702182769775 2.2852502846717835 79002 [0.0001, 0.0001] 3108.9710471630096\n",
      "80000 2.334803819656372 2.2858343160152437 80002 [0.0001, 0.0001] 3148.9924054145813\n",
      "81000 2.2984564304351807 2.2840614476203918 81002 [0.0001, 0.0001] 3186.8431684970856\n",
      "82000 2.273571729660034 2.2843041763305663 82002 [0.0001, 0.0001] 3226.383474111557\n",
      "83000 2.283252716064453 2.2846251521110537 83002 [0.0001, 0.0001] 3266.203445672989\n",
      "84000 2.3012328147888184 2.28389488863945 84002 [0.0001, 0.0001] 3305.859879732132\n",
      "85000 2.2815756797790527 2.283668046236038 85002 [0.0001, 0.0001] 3345.57261800766\n",
      "86000 2.2998759746551514 2.283955633878708 86002 [0.0001, 0.0001] 3385.1515872478485\n",
      "87000 2.29335618019104 2.281840679883957 87002 [0.0001, 0.0001] 3424.92294549942\n",
      "88000 2.312692642211914 2.282754477262497 88002 [0.0001, 0.0001] 3464.5798332691193\n",
      "89000 2.2954964637756348 2.2839604353904726 89002 [0.0001, 0.0001] 3504.1494328975677\n",
      "90000 2.3275272846221924 2.2840946803092956 90002 [0.0001, 0.0001] 3543.0988438129425\n",
      "91000 2.324995994567871 2.280599052667618 91002 [0.0001, 0.0001] 3581.640525341034\n",
      "92000 2.2382073402404785 2.281129793405533 92002 [0.0001, 0.0001] 3620.151686191559\n",
      "93000 2.2452328205108643 2.2788449482917787 93002 [0.0001, 0.0001] 3659.752319574356\n",
      "94000 2.3677237033843994 2.2805378103256224 94002 [0.0001, 0.0001] 3699.415568113327\n",
      "95000 2.2681796550750732 2.2806066210269926 95002 [0.0001, 0.0001] 3737.119384765625\n",
      "96000 2.2971110343933105 2.279728439092636 96002 [0.0001, 0.0001] 3776.0949115753174\n",
      "97000 2.289032459259033 2.278456520318985 97002 [0.0001, 0.0001] 3815.70001578331\n",
      "98000 2.1950156688690186 2.2775300455093386 98002 [0.0001, 0.0001] 3855.771510362625\n",
      "99000 2.203613758087158 2.2761663739681244 99002 [0.0001, 0.0001] 3894.2958476543427\n",
      "100000 2.188370943069458 2.276540692329407 100002 [0.0001, 0.0001] 3933.7912957668304\n",
      "101000 2.2635231018066406 2.2757884809970856 101002 [0.0001, 0.0001] 3973.643518447876\n",
      "102000 2.29325795173645 2.273046536922455 102002 [0.0001, 0.0001] 4013.4073100090027\n",
      "103000 2.244328498840332 2.27365949177742 103002 [0.0001, 0.0001] 4051.9845910072327\n",
      "104000 2.3159401416778564 2.2727430317401884 104002 [0.0001, 0.0001] 4091.3914675712585\n",
      "105000 2.240546226501465 2.271838708639145 105002 [0.0001, 0.0001] 4131.346905946732\n",
      "106000 2.2174878120422363 2.2698691391944887 106002 [0.0001, 0.0001] 4171.262985706329\n",
      "107000 2.2920570373535156 2.269330135822296 107002 [0.0001, 0.0001] 4211.278776168823\n",
      "108000 2.242540121078491 2.2695963199138642 108002 [0.0001, 0.0001] 4251.170703649521\n",
      "109000 2.2185568809509277 2.2673971951007843 109002 [0.0001, 0.0001] 4291.136227846146\n",
      "110000 2.2737953662872314 2.266729302883148 110002 [0.0001, 0.0001] 4330.782878637314\n",
      "111000 2.267385959625244 2.2650474088191985 111002 [0.0001, 0.0001] 4370.824679136276\n",
      "112000 2.285518169403076 2.2618853719234466 112002 [0.0001, 0.0001] 4410.762917041779\n",
      "113000 2.249565601348877 2.2610163407325743 113002 [0.0001, 0.0001] 4450.640504360199\n",
      "114000 2.3120768070220947 2.2595844421386717 114002 [0.0001, 0.0001] 4490.727715015411\n",
      "115000 2.225621461868286 2.258911929130554 115002 [0.0001, 0.0001] 4530.223767757416\n",
      "116000 2.2942566871643066 2.2544883260726927 116002 [0.0001, 0.0001] 4570.083606958389\n",
      "117000 2.2950313091278076 2.2543224680423735 117002 [0.0001, 0.0001] 4609.412095785141\n",
      "118000 2.30666446685791 2.2519621200561524 118002 [0.0001, 0.0001] 4648.6558628082275\n",
      "119000 2.2826473712921143 2.251876406669617 119002 [0.0001, 0.0001] 4688.558650970459\n",
      "120000 2.237476110458374 2.248115415096283 120002 [0.0001, 0.0001] 4727.826299667358\n",
      "121000 2.2893283367156982 2.2459977989196775 121002 [0.0001, 0.0001] 4767.48791384697\n",
      "122000 2.208138942718506 2.2428476474285124 122002 [0.0001, 0.0001] 4807.2476263046265\n",
      "123000 2.2209322452545166 2.2417940378189085 123002 [0.0001, 0.0001] 4846.90808224678\n",
      "124000 2.2168595790863037 2.237839876413345 124002 [0.0001, 0.0001] 4886.554372549057\n",
      "125000 2.236344575881958 2.2382826390266417 125002 [0.0001, 0.0001] 4926.148544549942\n",
      "126000 2.229374647140503 2.233353101968765 126002 [0.0001, 0.0001] 4966.13578414917\n",
      "127000 2.248375415802002 2.2310699315071107 127002 [0.0001, 0.0001] 5006.231466293335\n",
      "128000 2.225314140319824 2.228667088508606 128002 [0.0001, 0.0001] 5046.228102684021\n",
      "129000 2.201359510421753 2.2262637441158293 129002 [0.0001, 0.0001] 5085.962354898453\n",
      "130000 2.2025978565216064 2.2244507105350495 130002 [0.0001, 0.0001] 5123.596238851547\n",
      "131000 2.25593638420105 2.220263244152069 131002 [0.0001, 0.0001] 5160.345741271973\n",
      "132000 2.1494572162628174 2.2168733351230623 132002 [0.0001, 0.0001] 5199.679702043533\n",
      "133000 2.240137815475464 2.213967886686325 133002 [0.0001, 0.0001] 5239.063152551651\n",
      "134000 2.2104885578155518 2.2095435259342193 134002 [0.0001, 0.0001] 5278.795250654221\n",
      "135000 2.1798248291015625 2.207883797645569 135002 [0.0001, 0.0001] 5318.5650680065155\n",
      "136000 2.2252116203308105 2.204795154809952 136002 [0.0001, 0.0001] 5358.417300224304\n",
      "137000 2.196598529815674 2.1997915771007537 137002 [0.0001, 0.0001] 5397.995146512985\n",
      "138000 2.215864419937134 2.1968301208019256 138002 [0.0001, 0.0001] 5437.998989105225\n",
      "139000 2.179124355316162 2.194387701034546 139002 [0.0001, 0.0001] 5476.0525233745575\n",
      "140000 2.2098066806793213 2.1880043170452117 140002 [0.0001, 0.0001] 5515.135925769806\n",
      "141000 2.1664087772369385 2.1844863448143004 141002 [0.0001, 0.0001] 5554.907696962357\n",
      "142000 2.175901412963867 2.1810091090202333 142002 [0.0001, 0.0001] 5594.75555896759\n",
      "143000 2.2218241691589355 2.1785799984931944 143002 [0.0001, 0.0001] 5634.723515748978\n",
      "144000 2.2003939151763916 2.174035306930542 144002 [0.0001, 0.0001] 5674.507629871368\n",
      "145000 2.1717331409454346 2.1713416340351106 145002 [0.0001, 0.0001] 5714.140382766724\n",
      "146000 2.1980159282684326 2.164311883687973 146002 [0.0001, 0.0001] 5753.987653493881\n",
      "147000 2.153461456298828 2.162687945842743 147002 [0.0001, 0.0001] 5793.747365951538\n",
      "148000 2.147263765335083 2.1576714046001433 148002 [0.0001, 0.0001] 5833.168442487717\n",
      "149000 2.123789072036743 2.1517636363506316 149002 [0.0001, 0.0001] 5871.599229812622\n",
      "150000 2.112438678741455 2.15055904340744 150002 [0.0001, 0.0001] 5911.575534105301\n",
      "151000 2.131343364715576 2.1414923746585846 151002 [0.0001, 0.0001] 5951.507935762405\n",
      "152000 2.1732358932495117 2.138422219514847 152002 [0.0001, 0.0001] 5991.251064300537\n",
      "153000 2.1424720287323 2.1338670902252197 153002 [0.0001, 0.0001] 6031.252585411072\n",
      "154000 2.136381149291992 2.127910061120987 154002 [0.0001, 0.0001] 6071.475363492966\n",
      "155000 2.191070795059204 2.1230847210884094 155002 [0.0001, 0.0001] 6110.574531316757\n",
      "156000 2.111840009689331 2.1202819831371307 156002 [0.0001, 0.0001] 6150.610856771469\n",
      "157000 2.1602864265441895 2.115762371182442 157002 [0.0001, 0.0001] 6190.646471977234\n",
      "158000 2.0777971744537354 2.1110851083993913 158002 [0.0001, 0.0001] 6230.612375736237\n",
      "159000 2.1210670471191406 2.103231846809387 159002 [0.0001, 0.0001] 6270.563201904297\n",
      "160000 2.1112704277038574 2.1000134942531585 160002 [0.0001, 0.0001] 6310.333926677704\n",
      "161000 2.073580265045166 2.0942566694021223 161002 [0.0001, 0.0001] 6349.931676626205\n",
      "162000 2.0802805423736572 2.0885028067827225 162002 [0.0001, 0.0001] 6389.701436758041\n",
      "163000 2.06933331489563 2.0813256298303604 163002 [0.0001, 0.0001] 6428.879425048828\n",
      "164000 2.037703514099121 2.077936482310295 164002 [0.0001, 0.0001] 6469.047060251236\n",
      "165000 2.129518508911133 2.071482973098755 165002 [0.0001, 0.0001] 6508.667946100235\n",
      "166000 2.064835786819458 2.067729054689407 166002 [0.0001, 0.0001] 6547.90797328949\n",
      "167000 2.0638906955718994 2.059090609788895 167002 [0.0001, 0.0001] 6586.018874883652\n",
      "168000 2.0545153617858887 2.055073006272316 168002 [0.0001, 0.0001] 6625.867044210434\n",
      "169000 2.0296292304992676 2.0504328598976134 169002 [0.0001, 0.0001] 6665.320676088333\n",
      "170000 2.0348868370056152 2.0450258626937865 170002 [0.0001, 0.0001] 6704.51146197319\n",
      "171000 2.060716390609741 2.0395103992223738 171002 [0.0001, 0.0001] 6744.180746078491\n",
      "172000 2.0380778312683105 2.0309820927381517 172002 [0.0001, 0.0001] 6783.76372885704\n",
      "173000 1.97001051902771 2.028094914674759 173002 [0.0001, 0.0001] 6823.615720748901\n",
      "174000 1.9636591672897339 2.0202885105609893 174002 [0.0001, 0.0001] 6863.392318725586\n",
      "175000 2.0433425903320312 2.0150446107387543 175002 [0.0001, 0.0001] 6901.8005492687225\n",
      "176000 2.0229077339172363 2.0090536400079726 176002 [0.0001, 0.0001] 6941.424358844757\n",
      "177000 1.97231924533844 2.0037355606555938 177002 [0.0001, 0.0001] 6979.67489695549\n",
      "178000 1.985709309577942 1.9959779912233353 178002 [0.0001, 0.0001] 7016.62894153595\n",
      "179000 1.98482084274292 1.9926434483528137 179002 [0.0001, 0.0001] 7053.718240022659\n",
      "180000 1.9550670385360718 1.9862556312084199 180002 [0.0001, 0.0001] 7092.060122966766\n",
      "181000 1.969427227973938 1.979843683719635 181002 [0.0001, 0.0001] 7131.7438843250275\n",
      "182000 1.963046669960022 1.9739271875619888 182002 [0.0001, 0.0001] 7171.518440008163\n",
      "183000 1.9753724336624146 1.9684296867847442 183002 [0.0001, 0.0001] 7211.233343362808\n",
      "184000 2.011683464050293 1.9611490560770035 184002 [0.0001, 0.0001] 7250.492191553116\n",
      "185000 1.9568957090377808 1.956472142457962 185002 [0.0001, 0.0001] 7290.016459941864\n",
      "186000 1.9775115251541138 1.9507493690252304 186002 [0.0001, 0.0001] 7329.451785802841\n",
      "187000 1.926803708076477 1.9431605520248414 187002 [0.0001, 0.0001] 7369.042243480682\n",
      "188000 1.8845975399017334 1.9348054971694946 188002 [0.0001, 0.0001] 7407.712613582611\n",
      "189000 1.8805345296859741 1.9307626107931137 189002 [0.0001, 0.0001] 7446.607201576233\n",
      "190000 1.922560453414917 1.928149824142456 190002 [0.0001, 0.0001] 7484.742831945419\n",
      "191000 1.9640623331069946 1.9179288021326064 191002 [0.0001, 0.0001] 7523.45144200325\n",
      "192000 1.9295952320098877 1.9120899294614793 192002 [0.0001, 0.0001] 7562.948204040527\n",
      "193000 1.9247140884399414 1.907212394952774 193002 [0.0001, 0.0001] 7602.536370515823\n",
      "194000 1.8680038452148438 1.9004855349063874 194002 [0.0001, 0.0001] 7641.058916568756\n",
      "195000 1.936618685722351 1.895164808988571 195002 [0.0001, 0.0001] 7680.731558084488\n",
      "196000 1.9377440214157104 1.887801562190056 196002 [0.0001, 0.0001] 7720.61948800087\n",
      "197000 1.9531728029251099 1.882678710103035 197002 [0.0001, 0.0001] 7759.034242391586\n",
      "198000 1.842699646949768 1.877095223069191 198002 [0.0001, 0.0001] 7798.65256357193\n",
      "199000 1.8991879224777222 1.871401626110077 199002 [0.0001, 0.0001] 7838.155198812485\n",
      "200000 1.8351081609725952 1.8662058402299881 200002 [0.0001, 0.0001] 7877.336055755615\n",
      "201000 1.8948073387145996 1.8589211428165435 201002 [0.0001, 0.0001] 7916.912223577499\n",
      "202000 1.8638519048690796 1.8529539149999619 202002 [0.0001, 0.0001] 7954.449582338333\n",
      "203000 1.7890466451644897 1.8467347103357314 203002 [0.0001, 0.0001] 7994.132207632065\n",
      "204000 1.830526351928711 1.8404081149101257 204002 [0.0001, 0.0001] 8033.01331615448\n",
      "205000 1.8213579654693604 1.8340851122140884 205002 [0.0001, 0.0001] 8072.256543397903\n",
      "206000 1.8648672103881836 1.8285778836011886 206002 [0.0001, 0.0001] 8112.2948162555695\n",
      "207000 1.7238714694976807 1.8215598059892655 207002 [0.0001, 0.0001] 8152.154925823212\n",
      "208000 1.794207215309143 1.8174616553783416 208002 [0.0001, 0.0001] 8191.160313129425\n",
      "209000 1.7953455448150635 1.809000269651413 209002 [0.0001, 0.0001] 8230.84788942337\n",
      "210000 1.8261890411376953 1.8037601543664932 210002 [0.0001, 0.0001] 8270.707065582275\n",
      "211000 1.7869504690170288 1.797786941766739 211002 [0.0001, 0.0001] 8310.742963314056\n",
      "212000 1.7721831798553467 1.7927425118684768 212002 [0.0001, 0.0001] 8350.635511159897\n",
      "213000 1.7587953805923462 1.7858322341442108 213002 [0.0001, 0.0001] 8390.599211454391\n",
      "214000 1.802385687828064 1.7797195981740952 214002 [0.0001, 0.0001] 8430.260731935501\n",
      "215000 1.7593172788619995 1.7750798735618591 215002 [0.0001, 0.0001] 8469.720832824707\n",
      "216000 1.736640453338623 1.7681608225107193 216002 [0.0001, 0.0001] 8509.324354410172\n",
      "217000 1.8245854377746582 1.763631651878357 217002 [0.0001, 0.0001] 8549.087838172913\n",
      "218000 1.7765374183654785 1.7554520869255066 218002 [0.0001, 0.0001] 8588.751183509827\n",
      "219000 1.748021125793457 1.7508636227846146 219002 [0.0001, 0.0001] 8628.805055618286\n",
      "220000 1.706506609916687 1.7440644980669022 220002 [0.0001, 0.0001] 8666.68814110756\n",
      "221000 1.721944808959961 1.743197242498398 221002 [0.0001, 0.0001] 8704.484454393387\n",
      "222000 1.7521495819091797 1.7325781905651092 222002 [0.0001, 0.0001] 8743.324387550354\n",
      "223000 1.669306993484497 1.7268081345558166 223002 [0.0001, 0.0001] 8782.627091884613\n",
      "224000 1.637621283531189 1.7218443595170976 224002 [0.0001, 0.0001] 8822.323579072952\n",
      "225000 1.6873847246170044 1.7160599838495254 225002 [0.0001, 0.0001] 8861.29514336586\n",
      "226000 1.748628854751587 1.7127570331096649 226002 [0.0001, 0.0001] 8900.721181869507\n",
      "227000 1.6959258317947388 1.7024774465560912 227002 [0.0001, 0.0001] 8939.87590956688\n",
      "228000 1.6835404634475708 1.6992951755523682 228002 [0.0001, 0.0001] 8978.879384279251\n",
      "229000 1.7001043558120728 1.6919973932504655 229002 [0.0001, 0.0001] 9018.47441148758\n",
      "230000 1.6711640357971191 1.6868627341985702 230002 [0.0001, 0.0001] 9058.111946344376\n",
      "231000 1.7208791971206665 1.6846600122451783 231002 [0.0001, 0.0001] 9097.732146501541\n",
      "232000 1.6520307064056396 1.6752224997282028 232002 [0.0001, 0.0001] 9137.54087638855\n",
      "233000 1.636317253112793 1.6690439550876617 233002 [0.0001, 0.0001] 9177.155846595764\n",
      "234000 1.7413885593414307 1.6644848964214325 234002 [0.0001, 0.0001] 9216.580388069153\n",
      "235000 1.7512110471725464 1.6602772099971772 235002 [0.0001, 0.0001] 9256.340689659119\n",
      "236000 1.6447691917419434 1.651892061471939 236002 [0.0001, 0.0001] 9296.228171110153\n",
      "237000 1.6041669845581055 1.6492410569190978 237002 [0.0001, 0.0001] 9335.835912704468\n",
      "238000 1.6376476287841797 1.6430373647212981 238002 [0.0001, 0.0001] 9375.439851760864\n",
      "239000 1.6156344413757324 1.6344587891101836 239002 [0.0001, 0.0001] 9415.204142332077\n",
      "240000 1.639333963394165 1.634961197257042 240002 [0.0001, 0.0001] 9454.884854078293\n",
      "241000 1.5644145011901855 1.6278958358764648 241002 [0.0001, 0.0001] 9491.587569952011\n",
      "242000 1.6244808435440063 1.6222250547409058 242002 [0.0001, 0.0001] 9531.092038869858\n",
      "243000 1.5843334197998047 1.6172335693836213 243002 [0.0001, 0.0001] 9570.764626979828\n",
      "244000 1.647917628288269 1.6115776987075805 244002 [0.0001, 0.0001] 9610.827486991882\n",
      "245000 1.541940450668335 1.6055802619457245 245002 [0.0001, 0.0001] 9650.334972381592\n",
      "246000 1.6459438800811768 1.5990794507265091 246002 [0.0001, 0.0001] 9690.27894115448\n",
      "247000 1.5652492046356201 1.592718546628952 247002 [0.0001, 0.0001] 9730.110127210617\n",
      "248000 1.551696538925171 1.5917759963274003 248002 [0.0001, 0.0001] 9770.060498952866\n",
      "249000 1.5749844312667847 1.581818728685379 249002 [0.0001, 0.0001] 9809.987071752548\n",
      "250000 1.5573112964630127 1.5776734877824783 250002 [0.0001, 0.0001] 9849.775693893433\n",
      "251000 1.5311585664749146 1.5716256312131882 251002 [0.0001, 0.0001] 9889.638836860657\n",
      "252000 1.5352479219436646 1.5670633771419524 252002 [0.0001, 0.0001] 9928.071862220764\n",
      "253000 1.561873197555542 1.5636097902059556 253002 [0.0001, 0.0001] 9968.022806167603\n",
      "254000 1.5617083311080933 1.5561703904867172 254002 [0.0001, 0.0001] 10006.451343297958\n",
      "255000 1.6212677955627441 1.5547799921035768 255002 [0.0001, 0.0001] 10046.063300848007\n",
      "256000 1.5321037769317627 1.547598405122757 256002 [0.0001, 0.0001] 10085.68288898468\n",
      "257000 1.4827266931533813 1.5448372591733932 257002 [0.0001, 0.0001] 10124.800585985184\n",
      "258000 1.5096445083618164 1.5382100014686584 258002 [0.0001, 0.0001] 10164.188762664795\n",
      "259000 1.4737681150436401 1.5351517018079757 259002 [0.0001, 0.0001] 10204.007302761078\n",
      "260000 1.5349444150924683 1.5291267799139023 260002 [0.0001, 0.0001] 10243.675680160522\n",
      "261000 1.4072561264038086 1.5213199669122697 261002 [0.0001, 0.0001] 10283.58279633522\n",
      "262000 1.4538861513137817 1.5195746130943297 262002 [0.0001, 0.0001] 10323.098751306534\n",
      "263000 1.6015563011169434 1.5144336515665053 263002 [0.0001, 0.0001] 10362.818906545639\n",
      "264000 1.4175639152526855 1.506550702571869 264002 [0.0001, 0.0001] 10402.409924507141\n",
      "265000 1.4666880369186401 1.5034844218492507 265002 [0.0001, 0.0001] 10441.682808160782\n",
      "266000 1.5120306015014648 1.5024294123649597 266002 [0.0001, 0.0001] 10481.514461755753\n",
      "267000 1.5578402280807495 1.4933301256895066 267002 [0.0001, 0.0001] 10521.116174936295\n",
      "268000 1.4748610258102417 1.488433084487915 268002 [0.0001, 0.0001] 10560.82382941246\n",
      "269000 1.5884093046188354 1.4840557106733323 269002 [0.0001, 0.0001] 10600.035231590271\n",
      "270000 1.527671217918396 1.4827667696475983 270002 [0.0001, 0.0001] 10638.84957742691\n",
      "271000 1.5428979396820068 1.4739838631153106 271002 [0.0001, 0.0001] 10678.351647138596\n",
      "272000 1.5518981218338013 1.4707113103866578 272002 [0.0001, 0.0001] 10718.170211076736\n",
      "273000 1.386182188987732 1.466762731552124 273002 [0.0001, 0.0001] 10755.615804195404\n",
      "274000 1.4764927625656128 1.4642429150342942 274002 [0.0001, 0.0001] 10795.347389698029\n",
      "275000 1.4306938648223877 1.4556833671331406 275002 [0.0001, 0.0001] 10834.172455072403\n",
      "276000 1.5632168054580688 1.455429656624794 276002 [0.0001, 0.0001] 10873.799833536148\n",
      "277000 1.4028263092041016 1.4481025785207748 277002 [0.0001, 0.0001] 10912.743873596191\n",
      "278000 1.4145692586898804 1.4455668708086014 278002 [0.0001, 0.0001] 10952.4748878479\n",
      "279000 1.4420433044433594 1.4394529186487197 279002 [0.0001, 0.0001] 10992.040487527847\n",
      "280000 1.4544206857681274 1.4334572281837463 280002 [0.0001, 0.0001] 11031.578946352005\n",
      "281000 1.354819416999817 1.4293613830804826 281002 [0.0001, 0.0001] 11071.559045314789\n",
      "282000 1.4404242038726807 1.4267205920219421 282002 [0.0001, 0.0001] 11111.367570877075\n",
      "283000 1.3612116575241089 1.4219454663991928 283002 [0.0001, 0.0001] 11150.998170852661\n",
      "284000 1.4311062097549438 1.4169524533748628 284002 [0.0001, 0.0001] 11190.743887424469\n",
      "285000 1.3885711431503296 1.4142861080169677 285002 [0.0001, 0.0001] 11230.244074106216\n",
      "286000 1.364421010017395 1.4088497384786607 286002 [0.0001, 0.0001] 11268.76260972023\n",
      "287000 1.372305989265442 1.4062859654426574 287002 [0.0001, 0.0001] 11304.771712064743\n",
      "288000 1.3642032146453857 1.4017226972579957 288002 [0.0001, 0.0001] 11344.37607383728\n",
      "289000 1.3990775346755981 1.3987781784534454 289002 [0.0001, 0.0001] 11384.120005607605\n",
      "290000 1.370004415512085 1.3915203467607498 290002 [0.0001, 0.0001] 11423.824701786041\n",
      "291000 1.3602173328399658 1.3894773327112198 291002 [0.0001, 0.0001] 11463.72800540924\n",
      "292000 1.383815050125122 1.3864634433984757 292002 [0.0001, 0.0001] 11503.188590765\n",
      "293000 1.389096736907959 1.3818265143632888 293002 [0.0001, 0.0001] 11542.854398012161\n",
      "294000 1.3399075269699097 1.3762393304109573 294002 [0.0001, 0.0001] 11582.940794944763\n",
      "295000 1.365729808807373 1.370739359140396 295002 [0.0001, 0.0001] 11622.939000844955\n",
      "296000 1.423209309577942 1.3700501002073289 296002 [0.0001, 0.0001] 11663.055445432663\n",
      "297000 1.3846991062164307 1.3669922699928283 297002 [0.0001, 0.0001] 11703.075856924057\n",
      "298000 1.3274141550064087 1.3601935695409775 298002 [0.0001, 0.0001] 11742.695054292679\n",
      "299000 1.361488699913025 1.3894131997823715 299002 [0.0001, 0.0001] 11781.100208044052\n",
      "300000 1.3616175651550293 1.355483338356018 300002 [0.0001, 0.0001] 11820.487723588943\n",
      "301000 1.3140027523040771 1.3499885075092315 301002 [0.0001, 0.0001] 11860.483582258224\n",
      "302000 1.3250401020050049 1.3451164042949677 302002 [0.0001, 0.0001] 11899.228081226349\n",
      "303000 1.3350027799606323 1.339925015091896 303002 [0.0001, 0.0001] 11938.663451910019\n",
      "304000 1.3866537809371948 1.3385847367048263 304002 [0.0001, 0.0001] 11978.34954571724\n",
      "305000 1.4206666946411133 1.335652671456337 305002 [0.0001, 0.0001] 12017.6557803154\n",
      "306000 1.3333592414855957 1.332097996354103 306002 [0.0001, 0.0001] 12057.176625013351\n",
      "307000 1.2935729026794434 1.3264253475666046 307002 [0.0001, 0.0001] 12092.975650310516\n",
      "308000 1.284461498260498 1.3237279475927353 308002 [0.0001, 0.0001] 12131.339267253876\n",
      "309000 1.2710514068603516 1.3204583191871644 309002 [0.0001, 0.0001] 12170.839391708374\n",
      "310000 1.2873491048812866 1.3150129061937332 310002 [0.0001, 0.0001] 12210.587484836578\n",
      "311000 1.3793052434921265 1.3114339163303375 311002 [0.0001, 0.0001] 12250.281219959259\n",
      "312000 1.323257565498352 1.307857451081276 312002 [0.0001, 0.0001] 12290.154951810837\n",
      "313000 1.275325059890747 1.3054488518238068 313002 [0.0001, 0.0001] 12329.955215454102\n",
      "314000 1.28141450881958 1.3017294985055923 314002 [0.0001, 0.0001] 12369.690515041351\n",
      "315000 1.2439392805099487 1.2972707090377809 315002 [0.0001, 0.0001] 12409.499657392502\n",
      "316000 1.2632713317871094 1.2976277846097946 316002 [0.0001, 0.0001] 12449.010657548904\n",
      "317000 1.4711005687713623 1.3639755656719208 317002 [0.0001, 0.0001] 12484.856151103973\n",
      "318000 1.2910139560699463 1.2967177641391754 318002 [0.0001, 0.0001] 12524.863521575928\n",
      "319000 1.3304665088653564 1.2841794880628585 319002 [0.0001, 0.0001] 12564.515933036804\n",
      "320000 1.283652901649475 1.2801562858819961 320002 [0.0001, 0.0001] 12603.91669344902\n",
      "321000 1.336966872215271 1.2779012694358827 321002 [0.0001, 0.0001] 12643.360486984253\n",
      "322000 1.2280322313308716 1.2743152269124984 322002 [0.0001, 0.0001] 12682.965257167816\n",
      "323000 1.2416291236877441 1.273912855863571 323002 [0.0001, 0.0001] 12722.599507570267\n",
      "324000 1.2431824207305908 1.267223643541336 324002 [0.0001, 0.0001] 12762.275049209595\n",
      "325000 1.2000319957733154 1.2618919570446014 325002 [0.0001, 0.0001] 12801.978662252426\n",
      "326000 1.2218780517578125 1.2614379526376724 326002 [0.0001, 0.0001] 12841.784304618835\n",
      "327000 1.2391973733901978 1.258405487537384 327002 [0.0001, 0.0001] 12880.862595319748\n",
      "328000 1.1992830038070679 1.259237561225891 328002 [0.0001, 0.0001] 12918.982181072235\n",
      "329000 1.2431190013885498 1.2528064031600952 329002 [0.0001, 0.0001] 12957.598850727081\n",
      "330000 1.3168646097183228 1.2489416786432266 330002 [0.0001, 0.0001] 12996.382183074951\n",
      "331000 1.2433912754058838 1.2452950047254563 331002 [0.0001, 0.0001] 13034.50592494011\n",
      "332000 1.2457956075668335 1.2432781424522399 332002 [0.0001, 0.0001] 13073.775906801224\n",
      "333000 1.2043676376342773 1.2399154304265976 333002 [0.0001, 0.0001] 13113.410640954971\n",
      "334000 1.2428230047225952 1.2361459058523179 334002 [0.0001, 0.0001] 13152.874978542328\n",
      "335000 1.3366475105285645 1.2316270533800124 335002 [0.0001, 0.0001] 13190.71975159645\n",
      "336000 1.2851721048355103 1.2321859501600265 336002 [0.0001, 0.0001] 13230.116542816162\n",
      "337000 1.2264105081558228 1.226970048069954 337002 [0.0001, 0.0001] 13269.928236722946\n",
      "338000 1.1657052040100098 1.2246822700500488 338002 [0.0001, 0.0001] 13308.039699316025\n",
      "339000 1.221855640411377 1.2201718940734863 339002 [0.0001, 0.0001] 13347.062603712082\n",
      "340000 1.232474446296692 1.2170785722732544 340002 [0.0001, 0.0001] 13386.961724281311\n",
      "341000 1.2390116453170776 1.2149387125968933 341002 [0.0001, 0.0001] 13426.580229997635\n",
      "342000 1.2042032480239868 1.2140274708271026 342002 [0.0001, 0.0001] 13465.592040777206\n",
      "343000 1.282328724861145 1.2086108837127685 343002 [0.0001, 0.0001] 13504.62645483017\n",
      "344000 1.304878830909729 1.2075814929008484 344002 [0.0001, 0.0001] 13544.113584041595\n",
      "345000 1.238242506980896 1.2050606602430343 345002 [0.0001, 0.0001] 13582.927570104599\n",
      "346000 1.1670961380004883 1.1982234143018722 346002 [0.0001, 0.0001] 13622.5596139431\n",
      "347000 1.1595220565795898 1.1983971166610718 347002 [0.0001, 0.0001] 13662.435458421707\n",
      "348000 1.2611082792282104 1.1956527911424637 348002 [0.0001, 0.0001] 13701.283821344376\n",
      "349000 1.283177137374878 1.191394590497017 349002 [0.0001, 0.0001] 13741.14742231369\n",
      "350000 1.1722074747085571 1.1892198262214662 350002 [0.0001, 0.0001] 13781.171606779099\n",
      "351000 1.132148027420044 1.1875744947195053 351002 [0.0001, 0.0001] 13821.230919837952\n",
      "352000 1.2070149183273315 1.1864429216384889 352002 [0.0001, 0.0001] 13861.052475214005\n",
      "353000 1.1695160865783691 1.1809470525979995 353002 [0.0001, 0.0001] 13899.543225049973\n",
      "354000 1.1750319004058838 1.179187497973442 354002 [0.0001, 0.0001] 13939.176755428314\n",
      "355000 1.1225438117980957 1.1740064685344695 355002 [0.0001, 0.0001] 13977.464557170868\n",
      "356000 1.129272222518921 1.175072093605995 356002 [0.0001, 0.0001] 14016.555118560791\n",
      "357000 1.1888538599014282 1.1693808139562607 357002 [0.0001, 0.0001] 14056.639619350433\n",
      "358000 1.1357805728912354 1.1699054744243622 358002 [0.0001, 0.0001] 14095.469608545303\n",
      "359000 1.214279294013977 1.166324742436409 359002 [0.0001, 0.0001] 14134.419792890549\n",
      "360000 1.136962890625 1.164896237373352 360002 [0.0001, 0.0001] 14173.751711130142\n",
      "361000 1.2674938440322876 1.1611455178260803 361002 [0.0001, 0.0001] 14212.8827085495\n",
      "362000 1.1452327966690063 1.1556216049194337 362002 [0.0001, 0.0001] 14251.014573097229\n",
      "363000 1.1274471282958984 1.1546104199290275 363002 [0.0001, 0.0001] 14290.9948990345\n",
      "364000 1.1446170806884766 1.151882208943367 364002 [0.0001, 0.0001] 14330.690965175629\n",
      "365000 1.0850284099578857 1.1505220423936844 365002 [0.0001, 0.0001] 14370.5549325943\n",
      "366000 1.182576298713684 1.1493427914381027 366002 [0.0001, 0.0001] 14410.523433685303\n",
      "367000 1.1023705005645752 1.1448781163692474 367002 [0.0001, 0.0001] 14449.883396863937\n",
      "368000 1.1774400472640991 1.1442705422639847 368002 [0.0001, 0.0001] 14489.38333439827\n",
      "369000 1.161352515220642 1.1408608916401863 369002 [0.0001, 0.0001] 14529.147555828094\n",
      "370000 1.222899317741394 1.1389218343496323 370002 [0.0001, 0.0001] 14568.520842075348\n",
      "371000 1.1613848209381104 1.135169651865959 371002 [0.0001, 0.0001] 14607.267798900604\n",
      "372000 1.1413050889968872 1.1347589818239212 372002 [0.0001, 0.0001] 14646.964190483093\n",
      "373000 1.0557217597961426 1.1306994940042496 373002 [0.0001, 0.0001] 14687.027038812637\n",
      "374000 1.0682250261306763 1.1300893041491509 374002 [0.0001, 0.0001] 14726.914830207825\n",
      "375000 1.1355159282684326 1.1373390459418298 375002 [0.0001, 0.0001] 14766.621451377869\n",
      "376000 1.1563868522644043 1.1263582862019539 376002 [0.0001, 0.0001] 14806.06286907196\n",
      "377000 1.147049069404602 1.1190748600959777 377002 [0.0001, 0.0001] 14845.911516427994\n",
      "378000 1.168375849723816 1.1199993606209755 378002 [0.0001, 0.0001] 14885.712247371674\n",
      "379000 1.1434274911880493 1.1168491166234016 379002 [0.0001, 0.0001] 14925.277346849442\n",
      "380000 1.1502106189727783 1.1140950645208358 380002 [0.0001, 0.0001] 14964.40311551094\n",
      "381000 1.1777410507202148 1.1142157099246979 381002 [0.0001, 0.0001] 15002.3853931427\n",
      "382000 1.0620051622390747 1.109189456284046 382002 [0.0001, 0.0001] 15041.803176164627\n",
      "383000 1.1418354511260986 1.1098655889630318 383002 [0.0001, 0.0001] 15081.295842409134\n",
      "384000 1.1216212511062622 1.107444184422493 384002 [0.0001, 0.0001] 15120.569195747375\n",
      "385000 1.1554110050201416 1.1034917201995849 385002 [0.0001, 0.0001] 15160.096404790878\n",
      "386000 1.1298810243606567 1.1021259996294974 386002 [0.0001, 0.0001] 15199.635699748993\n",
      "387000 1.086784839630127 1.1022310886979103 387002 [0.0001, 0.0001] 15238.227629899979\n",
      "388000 1.092265009880066 1.0954518854022026 388002 [0.0001, 0.0001] 15277.275212049484\n",
      "389000 1.0617637634277344 1.0952348943948746 389002 [0.0001, 0.0001] 15316.43566274643\n",
      "390000 1.0260612964630127 1.092941077888012 390002 [0.0001, 0.0001] 15355.240028619766\n",
      "391000 1.0233240127563477 1.0904588751196862 391002 [0.0001, 0.0001] 15394.531661987305\n",
      "392000 1.0824629068374634 1.089689933180809 392002 [0.0001, 0.0001] 15433.43231678009\n",
      "393000 1.0984456539154053 1.0874318143725394 393002 [0.0001, 0.0001] 15472.964271783829\n",
      "394000 1.0853700637817383 1.0809916989803314 394002 [0.0001, 0.0001] 15512.271713733673\n",
      "395000 1.0540167093276978 1.0816439224481582 395002 [0.0001, 0.0001] 15551.85208439827\n",
      "396000 1.0821806192398071 1.0824886415600776 396002 [0.0001, 0.0001] 15591.319857120514\n",
      "397000 1.105278491973877 1.081752258002758 397002 [0.0001, 0.0001] 15630.81063747406\n",
      "398000 0.9485093355178833 1.0754502577781677 398002 [0.0001, 0.0001] 15670.046934604645\n",
      "399000 1.082019329071045 1.0749873968362809 399002 [0.0001, 0.0001] 15708.999684810638\n",
      "400000 1.0359866619110107 1.0716280438303947 400002 [0.0001, 0.0001] 15748.934180021286\n",
      "401000 1.1408452987670898 1.0741042932271958 401002 [0.0001, 0.0001] 15788.760090112686\n",
      "402000 1.0372315645217896 1.0655266741514207 402002 [0.0001, 0.0001] 15828.187904596329\n",
      "403000 1.0265626907348633 1.0640867718458176 403002 [0.0001, 0.0001] 15867.739273071289\n",
      "404000 1.0832937955856323 1.0649320437312126 404002 [0.0001, 0.0001] 15907.667225122452\n",
      "405000 1.072003960609436 1.0657715201377869 405002 [0.0001, 0.0001] 15947.658973932266\n",
      "406000 1.0051451921463013 1.0603915696144104 406002 [0.0001, 0.0001] 15987.499302148819\n",
      "407000 1.0419222116470337 1.059573810338974 407002 [0.0001, 0.0001] 16027.300160884857\n",
      "408000 1.089239239692688 1.054876731455326 408002 [0.0001, 0.0001] 16067.111931562424\n",
      "409000 1.090332269668579 1.0567491691112518 409002 [0.0001, 0.0001] 16106.948659420013\n",
      "410000 1.0626164674758911 1.05302517080307 410002 [0.0001, 0.0001] 16146.579649209976\n",
      "411000 1.0848115682601929 1.051585891187191 411002 [0.0001, 0.0001] 16185.407419681549\n",
      "412000 1.0261298418045044 1.0529332694411278 412002 [0.0001, 0.0001] 16225.036413669586\n",
      "413000 0.9976707696914673 1.048445635676384 413002 [0.0001, 0.0001] 16264.784789323807\n",
      "414000 1.0286353826522827 1.0482009073495866 414002 [0.0001, 0.0001] 16303.8196849823\n",
      "415000 0.9892646670341492 1.045373722076416 415002 [0.0001, 0.0001] 16343.100058317184\n",
      "416000 1.0628602504730225 1.045781808435917 416002 [0.0001, 0.0001] 16382.6034450531\n",
      "417000 1.0343140363693237 1.0390933324098588 417002 [0.0001, 0.0001] 16422.199914216995\n",
      "418000 0.9659523963928223 1.0407243772745132 418002 [0.0001, 0.0001] 16461.704015254974\n",
      "419000 1.0338088274002075 1.0389862203598021 419002 [0.0001, 0.0001] 16499.2518286705\n",
      "420000 1.0828739404678345 1.0348803616166116 420002 [0.0001, 0.0001] 16538.772711753845\n",
      "421000 1.080431580543518 1.0333646004796029 421002 [0.0001, 0.0001] 16578.523838996887\n",
      "422000 1.0056185722351074 1.0346961936950683 422002 [0.0001, 0.0001] 16618.439666748047\n",
      "423000 1.0094553232192993 1.0307373653054237 423002 [0.0001, 0.0001] 16658.231098890305\n",
      "424000 0.9632844924926758 1.0262486305832863 424002 [0.0001, 0.0001] 16696.892733335495\n",
      "425000 1.087265968322754 1.0266249068975448 425002 [0.0001, 0.0001] 16735.55673122406\n",
      "426000 0.9873015880584717 1.024064693927765 426002 [0.0001, 0.0001] 16775.375145196915\n",
      "427000 1.0209800004959106 1.0230051863193512 427002 [0.0001, 0.0001] 16814.75269317627\n",
      "428000 1.0447603464126587 1.019625165104866 428002 [0.0001, 0.0001] 16854.248091459274\n",
      "429000 1.0063225030899048 1.0200909242630005 429002 [0.0001, 0.0001] 16891.465683698654\n",
      "430000 1.0457690954208374 1.0204440437555313 430002 [0.0001, 0.0001] 16928.44344162941\n",
      "431000 0.8978851437568665 1.0135005727410316 431002 [0.0001, 0.0001] 16964.482290506363\n",
      "432000 1.0114521980285645 1.0145498263835906 432002 [0.0001, 0.0001] 17003.195673942566\n",
      "433000 1.0125967264175415 1.014528907239437 433002 [0.0001, 0.0001] 17042.7075612545\n",
      "434000 1.0445938110351562 1.012739592075348 434002 [0.0001, 0.0001] 17082.00618815422\n",
      "435000 0.885258674621582 1.009596213042736 435002 [0.0001, 0.0001] 17120.773476839066\n",
      "436000 1.0131586790084839 1.0096260293126107 436002 [0.0001, 0.0001] 17160.259658813477\n",
      "437000 0.9755682945251465 1.0109270293712616 437002 [0.0001, 0.0001] 17199.91011428833\n",
      "438000 0.9142846465110779 1.006612365782261 438002 [0.0001, 0.0001] 17239.61656475067\n",
      "439000 0.9261510372161865 1.004746224284172 439002 [0.0001, 0.0001] 17279.21070957184\n",
      "440000 1.3821966648101807 1.0609158194661141 440002 [0.0001, 0.0001] 17318.707753181458\n",
      "441000 1.0118452310562134 1.0215510286688805 441002 [0.0001, 0.0001] 17357.895868062973\n",
      "442000 1.058823585510254 0.9977086125016212 442002 [0.0001, 0.0001] 17397.130929470062\n",
      "443000 0.9509254693984985 1.00112511074543 443002 [0.0001, 0.0001] 17435.472126960754\n",
      "444000 1.054667592048645 1.0000825162529945 444002 [0.0001, 0.0001] 17474.7475502491\n",
      "445000 1.0251667499542236 1.0004223445653915 445002 [0.0001, 0.0001] 17514.20563864708\n",
      "446000 1.009982705116272 0.9945998208522797 446002 [0.0001, 0.0001] 17553.787967920303\n",
      "447000 0.9753652215003967 0.9903242077827453 447002 [0.0001, 0.0001] 17592.437113761902\n",
      "448000 1.0328010320663452 0.9942027904391288 448002 [0.0001, 0.0001] 17631.840000152588\n",
      "449000 1.002989411354065 0.9902670336961746 449002 [0.0001, 0.0001] 17671.36130642891\n",
      "450000 1.0292009115219116 0.9880969034433364 450002 [0.0001, 0.0001] 17710.73150587082\n",
      "451000 0.9506555199623108 0.9894148649573327 451002 [0.0001, 0.0001] 17749.904740333557\n",
      "452000 1.0150638818740845 0.9869479348063469 452002 [0.0001, 0.0001] 17788.998859643936\n",
      "453000 0.9972314834594727 0.9835870389938355 453002 [0.0001, 0.0001] 17828.075551748276\n",
      "454000 1.0688472986221313 0.980889968752861 454002 [0.0001, 0.0001] 17867.332159996033\n",
      "455000 0.9450955390930176 0.9834736047983169 455002 [0.0001, 0.0001] 17906.81258201599\n",
      "456000 1.0402730703353882 0.9816211701631546 456002 [0.0001, 0.0001] 17946.719295740128\n",
      "457000 0.978553056716919 0.982016143977642 457002 [0.0001, 0.0001] 17986.276232481003\n",
      "458000 0.961741030216217 0.9774531129598617 458002 [0.0001, 0.0001] 18025.92343187332\n",
      "459000 0.9662002325057983 0.9739981280565262 459002 [0.0001, 0.0001] 18065.620281934738\n",
      "460000 1.0265203714370728 0.9736193253993988 460002 [0.0001, 0.0001] 18105.17214345932\n",
      "461000 0.9063690900802612 0.9754107445478439 461002 [0.0001, 0.0001] 18141.84516096115\n",
      "462000 0.9404889941215515 0.9721389951109887 462002 [0.0001, 0.0001] 18178.95138645172\n",
      "463000 1.0109069347381592 0.9715234545469285 463002 [0.0001, 0.0001] 18218.16391968727\n",
      "464000 0.9787390828132629 0.9710305291414261 464002 [0.0001, 0.0001] 18257.643675088882\n",
      "465000 0.9437861442565918 0.9675054415464401 465002 [0.0001, 0.0001] 18297.132915973663\n",
      "466000 0.9739124178886414 0.9689176229834556 466002 [0.0001, 0.0001] 18336.755166053772\n",
      "467000 0.9967064261436462 0.96405897128582 467002 [0.0001, 0.0001] 18376.623158216476\n",
      "468000 0.8646014928817749 0.9645886280536652 468002 [0.0001, 0.0001] 18415.763126134872\n",
      "469000 0.9379675984382629 0.9633370177149773 469002 [0.0001, 0.0001] 18455.154756069183\n",
      "470000 0.9470012187957764 0.9619913586974144 470002 [0.0001, 0.0001] 18495.015664339066\n",
      "471000 0.9220460653305054 0.9598446101546287 471002 [0.0001, 0.0001] 18535.070905685425\n",
      "472000 1.0204218626022339 0.9611634368300438 472002 [0.0001, 0.0001] 18574.4029211998\n",
      "473000 0.9526717662811279 0.955224995970726 473002 [0.0001, 0.0001] 18614.34801697731\n",
      "474000 0.9946012496948242 0.9576118239164353 474002 [0.0001, 0.0001] 18654.175854444504\n",
      "475000 0.9450826048851013 0.9556813371777535 475002 [0.0001, 0.0001] 18693.923964500427\n",
      "476000 1.0407289266586304 0.956244288444519 476002 [0.0001, 0.0001] 18733.320178985596\n",
      "477000 0.9229830503463745 0.956097837626934 477002 [0.0001, 0.0001] 18772.99178338051\n",
      "478000 0.9638820290565491 0.9520475513339043 478002 [0.0001, 0.0001] 18812.868215084076\n",
      "479000 1.0119695663452148 0.9537259790301323 479002 [0.0001, 0.0001] 18852.380408525467\n",
      "480000 0.977155864238739 0.9482662354111672 480002 [0.0001, 0.0001] 18891.76815891266\n",
      "481000 0.8768759965896606 0.9491332434415817 481002 [0.0001, 0.0001] 18931.343183279037\n",
      "482000 0.9453356266021729 0.9465152318477631 482002 [0.0001, 0.0001] 18970.59687280655\n",
      "483000 0.9854063391685486 0.9457623168826104 483002 [0.0001, 0.0001] 19008.960035324097\n",
      "484000 0.9552582502365112 0.9464664514064789 484002 [0.0001, 0.0001] 19048.300001621246\n",
      "485000 0.9392118453979492 0.9441880875229836 485002 [0.0001, 0.0001] 19087.903903722763\n",
      "486000 1.039062261581421 0.9430170998573303 486002 [0.0001, 0.0001] 19127.548757076263\n",
      "487000 0.9378125667572021 0.9421616867780686 487002 [0.0001, 0.0001] 19167.0626308918\n",
      "488000 0.9199826121330261 0.9401365368366241 488002 [0.0001, 0.0001] 19202.594757318497\n",
      "489000 1.0059524774551392 0.9391153097748757 489002 [0.0001, 0.0001] 19240.388020277023\n",
      "490000 0.9173503518104553 0.9384778134822845 490002 [0.0001, 0.0001] 19279.936202049255\n",
      "491000 1.0167169570922852 0.9391610102057457 491002 [0.0001, 0.0001] 19318.983340024948\n",
      "492000 0.8800893425941467 0.9347669818997383 492002 [0.0001, 0.0001] 19358.3790102005\n",
      "493000 1.0473582744598389 0.9352713152766228 493002 [0.0001, 0.0001] 19398.370688438416\n",
      "494000 0.8579434156417847 0.935502293765545 494002 [0.0001, 0.0001] 19438.295586824417\n",
      "495000 0.9719081521034241 0.9337272501587868 495002 [0.0001, 0.0001] 19478.015320777893\n",
      "496000 0.9388344287872314 0.9346868238449096 496002 [0.0001, 0.0001] 19516.682898521423\n",
      "497000 0.8807124495506287 0.9287437354326248 497002 [0.0001, 0.0001] 19553.08416390419\n",
      "498000 0.9890570640563965 0.9326934522390365 498002 [0.0001, 0.0001] 19592.69578742981\n",
      "499000 0.866386890411377 0.9290857105255127 499002 [0.0001, 0.0001] 19630.528153181076\n",
      "500000 0.9420304894447327 0.9271287151575088 500002 [0.0001, 0.0001] 19669.96764945984\n",
      "501000 0.9361950159072876 0.9261611805558204 501002 [0.0001, 0.0001] 19708.675737142563\n",
      "502000 0.9204459190368652 0.9277540327906608 502002 [0.0001, 0.0001] 19748.252588510513\n",
      "503000 0.9252132177352905 0.9260811625719071 503002 [0.0001, 0.0001] 19787.80818796158\n",
      "504000 0.9639880061149597 0.9252945764660835 504002 [0.0001, 0.0001] 19827.279956817627\n",
      "505000 0.8765293955802917 0.9242104725241661 505002 [0.0001, 0.0001] 19866.6728143692\n",
      "506000 0.9553583264350891 0.9200797725319863 506002 [0.0001, 0.0001] 19906.19277071953\n",
      "507000 0.9153837561607361 0.9208763964772224 507002 [0.0001, 0.0001] 19945.88781929016\n",
      "508000 1.0068477392196655 0.9202816146016121 508002 [0.0001, 0.0001] 19985.2937002182\n",
      "509000 0.8785678744316101 0.9186719372868538 509002 [0.0001, 0.0001] 20021.98133945465\n",
      "510000 0.881396472454071 0.9157020196914673 510002 [0.0001, 0.0001] 20061.557212352753\n",
      "511000 0.9071832895278931 0.917633417904377 511002 [0.0001, 0.0001] 20100.759865045547\n",
      "512000 0.9428653717041016 0.915369968354702 512002 [0.0001, 0.0001] 20140.296618700027\n",
      "513000 0.9093517661094666 0.914209770321846 513002 [0.0001, 0.0001] 20179.64001274109\n",
      "514000 0.8749232292175293 0.9126134912967682 514002 [0.0001, 0.0001] 20219.45588374138\n",
      "515000 0.9759127497673035 0.9126721556782722 515002 [0.0001, 0.0001] 20256.482778787613\n",
      "516000 0.8443540930747986 0.9130582025051117 516002 [0.0001, 0.0001] 20295.77149772644\n",
      "517000 0.9602323770523071 0.9116129250526428 517002 [0.0001, 0.0001] 20335.40780878067\n",
      "518000 0.9114682674407959 0.9165176684856415 518002 [0.0001, 0.0001] 20374.639994859695\n",
      "519000 0.8962184190750122 0.9077172839641571 519002 [0.0001, 0.0001] 20414.29236793518\n",
      "520000 0.8856213688850403 0.9086377338767052 520002 [0.0001, 0.0001] 20453.683440446854\n",
      "521000 0.9131430983543396 0.9060028036236762 521002 [0.0001, 0.0001] 20491.208858013153\n",
      "522000 0.8763975501060486 0.90899882209301 522002 [0.0001, 0.0001] 20527.675889253616\n",
      "523000 0.8436540961265564 0.9039908445477486 523002 [0.0001, 0.0001] 20567.15245103836\n",
      "524000 0.8922294974327087 0.905982639670372 524002 [0.0001, 0.0001] 20605.910766363144\n",
      "525000 0.9142967462539673 0.9051825374364852 525002 [0.0001, 0.0001] 20642.22409939766\n",
      "526000 0.9632114171981812 0.9021754526495933 526002 [0.0001, 0.0001] 20680.763209342957\n",
      "527000 0.9623305797576904 0.9005818240642548 527002 [0.0001, 0.0001] 20720.538865566254\n",
      "528000 0.9066370129585266 0.9007478648424149 528002 [0.0001, 0.0001] 20760.53902220726\n",
      "529000 0.9507730007171631 0.9016941613554954 529002 [0.0001, 0.0001] 20799.62828183174\n",
      "530000 0.876262903213501 0.9021794571876526 530002 [0.0001, 0.0001] 20838.4285364151\n",
      "531000 0.9179122447967529 0.8970519317388534 531002 [0.0001, 0.0001] 20877.68750667572\n",
      "532000 0.8903717994689941 0.8957828357219696 532002 [0.0001, 0.0001] 20917.57125043869\n",
      "533000 0.9189105033874512 0.8959832460284233 533002 [0.0001, 0.0001] 20956.891851186752\n",
      "534000 0.9018334746360779 0.8956216042041778 534002 [0.0001, 0.0001] 20995.74750685692\n",
      "535000 0.8784383535385132 0.8957483555674552 535002 [0.0001, 0.0001] 21035.128215312958\n",
      "536000 0.8986983895301819 0.8950967069864273 536002 [0.0001, 0.0001] 21074.96747112274\n",
      "537000 0.8649522662162781 0.8953033891320229 537002 [0.0001, 0.0001] 21114.59086251259\n",
      "538000 0.9130815267562866 0.8920760530829429 538002 [0.0001, 0.0001] 21154.551523685455\n",
      "539000 0.9056007862091064 0.8909591263532639 539002 [0.0001, 0.0001] 21194.280107975006\n",
      "540000 0.847031831741333 0.8919136351943016 540002 [0.0001, 0.0001] 21232.839958906174\n",
      "541000 0.9171332716941833 0.8915105915665626 541002 [0.0001, 0.0001] 21271.952414512634\n",
      "542000 0.8994362354278564 0.8908176618814468 542002 [0.0001, 0.0001] 21310.90461063385\n",
      "543000 0.8845018148422241 0.8870763193368911 543002 [0.0001, 0.0001] 21350.755820274353\n",
      "544000 0.8883997201919556 0.8863032109737397 544002 [0.0001, 0.0001] 21390.81517481804\n",
      "545000 0.8915791511535645 0.8858345574140549 545002 [0.0001, 0.0001] 21430.11142015457\n",
      "546000 0.8718015551567078 0.8892844413518906 546002 [0.0001, 0.0001] 21469.655747890472\n",
      "547000 0.8776198029518127 0.8845884190797806 547002 [0.0001, 0.0001] 21509.61202263832\n",
      "548000 0.8878077268600464 0.8843189823627472 548002 [0.0001, 0.0001] 21549.1760802269\n",
      "549000 0.8686797618865967 0.8843643221259118 549002 [0.0001, 0.0001] 21587.903619766235\n",
      "550000 0.9318850040435791 0.8818202555775643 550002 [0.0001, 0.0001] 21627.680052757263\n",
      "551000 0.9258547425270081 0.8820876649022102 551002 [0.0001, 0.0001] 21667.55108141899\n",
      "552000 0.8999177813529968 0.8828887262940407 552002 [0.0001, 0.0001] 21707.071960926056\n",
      "553000 0.8659787178039551 0.8823523820638657 553002 [0.0001, 0.0001] 21746.816888809204\n",
      "554000 0.9075739979743958 0.8788971043229103 554002 [0.0001, 0.0001] 21786.36433506012\n",
      "555000 0.8912832736968994 0.8778457948565483 555002 [0.0001, 0.0001] 21824.86753845215\n",
      "556000 0.8481152653694153 0.8777528486847878 556002 [0.0001, 0.0001] 21863.9433054924\n",
      "557000 0.8648481965065002 0.8759191817045212 557002 [0.0001, 0.0001] 21903.90357685089\n",
      "558000 0.8355551958084106 0.8778512082695961 558002 [0.0001, 0.0001] 21942.65243792534\n",
      "559000 0.8755282759666443 0.8763958251476288 559002 [0.0001, 0.0001] 21981.76249885559\n",
      "560000 0.8267706632614136 0.8738108100891113 560002 [0.0001, 0.0001] 22020.65878891945\n",
      "561000 0.8767719864845276 0.8735877166986465 561002 [0.0001, 0.0001] 22060.586758852005\n",
      "562000 0.9955112934112549 0.8739033768773079 562002 [0.0001, 0.0001] 22100.1353597641\n",
      "563000 0.9192076325416565 0.872335482954979 563002 [0.0001, 0.0001] 22140.021300792694\n",
      "564000 0.9363260269165039 0.8742448931932449 564002 [0.0001, 0.0001] 22179.135314941406\n",
      "565000 0.9213141202926636 0.8722901836633682 565002 [0.0001, 0.0001] 22218.29563331604\n",
      "566000 0.842479407787323 0.8674955389499664 566002 [0.0001, 0.0001] 22258.024026870728\n",
      "567000 0.9097724556922913 0.8681901393532753 567002 [0.0001, 0.0001] 22297.343603134155\n",
      "568000 0.825812578201294 0.8721031818389893 568002 [0.0001, 0.0001] 22336.719636678696\n",
      "569000 0.9412350654602051 0.8687499031424523 569002 [0.0001, 0.0001] 22376.175794363022\n",
      "570000 0.858941376209259 0.8671579731702804 570002 [0.0001, 0.0001] 22415.48516702652\n",
      "571000 0.8231925964355469 0.8671418693065643 571002 [0.0001, 0.0001] 22454.5400660038\n",
      "572000 0.9655017256736755 0.8658331907987594 572002 [0.0001, 0.0001] 22494.21901535988\n",
      "573000 0.9009525179862976 0.8643350932002067 573002 [0.0001, 0.0001] 22534.08150935173\n",
      "574000 0.8749514222145081 0.8640615388154983 574002 [0.0001, 0.0001] 22573.72808456421\n",
      "575000 0.8718721866607666 0.8629899483919143 575002 [0.0001, 0.0001] 22613.14074397087\n",
      "576000 0.9145172834396362 0.8623664395809174 576002 [0.0001, 0.0001] 22653.03584766388\n",
      "577000 0.8705597519874573 0.8608997519016266 577002 [0.0001, 0.0001] 22692.765086889267\n",
      "578000 0.9516947865486145 0.8610489454865455 578002 [0.0001, 0.0001] 22729.236679553986\n",
      "579000 0.889187753200531 0.8633186053037644 579002 [0.0001, 0.0001] 22767.45178794861\n",
      "580000 0.8199812769889832 0.8601605001091958 580002 [0.0001, 0.0001] 22807.30724787712\n",
      "581000 0.8746609687805176 0.8618533474206924 581002 [0.0001, 0.0001] 22846.963862657547\n",
      "582000 0.8756880760192871 0.8593509794473648 582002 [0.0001, 0.0001] 22886.441343545914\n",
      "583000 0.8371689319610596 0.8558906715512276 583002 [0.0001, 0.0001] 22926.00504875183\n",
      "584000 0.8684537410736084 0.8582769340872765 584002 [0.0001, 0.0001] 22965.50010585785\n",
      "585000 0.8614766597747803 0.8552101781368255 585002 [0.0001, 0.0001] 23005.61865901947\n",
      "586000 0.8890153765678406 0.855277981698513 586002 [0.0001, 0.0001] 23045.67394208908\n",
      "587000 0.8323368430137634 0.8565504719614982 587002 [0.0001, 0.0001] 23085.64754319191\n",
      "588000 0.9426576495170593 0.8556174942851067 588002 [0.0001, 0.0001] 23125.588385105133\n",
      "589000 0.8182756304740906 0.8554362800717353 589002 [0.0001, 0.0001] 23164.17971420288\n",
      "590000 0.8267208337783813 0.8536109627485275 590002 [0.0001, 0.0001] 23203.428288459778\n",
      "591000 0.9182003736495972 0.853738007247448 591002 [0.0001, 0.0001] 23243.41508936882\n",
      "592000 0.8616712689399719 0.8531900129914284 592002 [0.0001, 0.0001] 23283.067741155624\n",
      "593000 0.8473554849624634 0.8510250531435013 593002 [0.0001, 0.0001] 23323.1353597641\n",
      "594000 0.841882586479187 0.8523747270703316 594002 [0.0001, 0.0001] 23362.832763671875\n",
      "595000 0.8294820189476013 0.8539455698132515 595002 [0.0001, 0.0001] 23402.31233716011\n",
      "596000 0.8847418427467346 0.8500615578889846 596002 [0.0001, 0.0001] 23441.843636751175\n",
      "597000 0.8412296175956726 0.8491308150887489 597002 [0.0001, 0.0001] 23481.667992830276\n",
      "598000 0.8278494477272034 0.8508893845677376 598002 [0.0001, 0.0001] 23521.24796462059\n",
      "599000 0.8496696949005127 0.8473404880166053 599002 [0.0001, 0.0001] 23560.73648762703\n",
      "600000 0.931796669960022 0.847821609377861 600002 [0.0001, 0.0001] 23600.055263519287\n",
      "601000 0.8532266020774841 0.8467855273485184 601002 [0.0001, 0.0001] 23639.596415042877\n",
      "602000 0.8826903700828552 0.8469147496223449 602002 [0.0001, 0.0001] 23679.29580593109\n",
      "603000 0.809881865978241 0.8481029955148697 603002 [0.0001, 0.0001] 23718.95577263832\n",
      "604000 0.8993939757347107 0.847427689731121 604002 [0.0001, 0.0001] 23758.65970826149\n",
      "605000 0.8424473404884338 0.8455373319983482 605002 [0.0001, 0.0001] 23797.625601530075\n",
      "606000 0.8685034513473511 0.8451312211751938 606002 [0.0001, 0.0001] 23837.352493047714\n",
      "607000 0.8119640946388245 0.8431294075250626 607002 [0.0001, 0.0001] 23876.194406747818\n",
      "608000 0.8775982856750488 0.844203179359436 608002 [0.0001, 0.0001] 23915.944191217422\n",
      "609000 0.814298689365387 0.8427335718870163 609002 [0.0001, 0.0001] 23953.368342876434\n",
      "610000 0.7898744940757751 0.8430175312757492 610002 [0.0001, 0.0001] 23991.087757349014\n",
      "611000 0.7992733716964722 0.8405611117482186 611002 [0.0001, 0.0001] 24031.099141597748\n",
      "612000 0.8297371864318848 0.8417601982951164 612002 [0.0001, 0.0001] 24071.359850168228\n",
      "613000 0.7654097080230713 0.8681612443327904 613002 [0.0001, 0.0001] 24111.039086580276\n",
      "614000 0.8142130970954895 0.8404627280831337 614002 [0.0001, 0.0001] 24151.05135846138\n",
      "615000 0.8346176147460938 0.8386297736167908 615002 [0.0001, 0.0001] 24190.851107358932\n",
      "616000 0.8183205723762512 0.8390747239589691 616002 [0.0001, 0.0001] 24230.43037891388\n",
      "617000 0.8167298436164856 0.839515643119812 617002 [0.0001, 0.0001] 24270.057376623154\n",
      "618000 0.8718323707580566 0.8363738971948623 618002 [0.0001, 0.0001] 24309.97514796257\n",
      "619000 0.8145278692245483 0.835677272439003 619002 [0.0001, 0.0001] 24349.96327137947\n",
      "620000 0.8186889290809631 0.8358051555156708 620002 [0.0001, 0.0001] 24389.726557016373\n",
      "621000 0.809368908405304 0.8385920628905297 621002 [0.0001, 0.0001] 24429.57484316826\n",
      "622000 0.865967333316803 0.8506370288133621 622002 [0.0001, 0.0001] 24468.96270799637\n",
      "623000 0.8392425179481506 0.8393214884400367 623002 [0.0001, 0.0001] 24508.72308754921\n",
      "624000 0.8721204996109009 0.8327955685257912 624002 [0.0001, 0.0001] 24548.151054143906\n",
      "625000 0.8435915112495422 0.8316920245289803 625002 [0.0001, 0.0001] 24587.870711803436\n",
      "626000 0.7592236995697021 0.8353090500831604 626002 [0.0001, 0.0001] 24627.412080287933\n",
      "627000 0.8702182769775391 0.8329893108606339 627002 [0.0001, 0.0001] 24666.857415914536\n",
      "628000 0.8482540249824524 0.8313809858560562 628002 [0.0001, 0.0001] 24706.59187412262\n",
      "629000 0.8158462047576904 0.8314108601212502 629002 [0.0001, 0.0001] 24746.370972394943\n",
      "630000 0.7569514513015747 0.8323588244318962 630002 [0.0001, 0.0001] 24785.495569705963\n",
      "631000 0.7897412776947021 0.8330460708737374 631002 [0.0001, 0.0001] 24825.048099040985\n",
      "632000 0.8090447187423706 0.8289448825120926 632002 [0.0001, 0.0001] 24864.835656166077\n",
      "633000 0.7822312116622925 0.8266390895843506 633002 [0.0001, 0.0001] 24904.17705845833\n",
      "634000 0.7748178839683533 0.8298534474372864 634002 [0.0001, 0.0001] 24943.743147850037\n",
      "635000 0.8454060554504395 0.8291275252699852 635002 [0.0001, 0.0001] 24983.382207155228\n",
      "636000 0.8164293766021729 0.8274728979468345 636002 [0.0001, 0.0001] 25023.068111896515\n",
      "637000 0.8217390775680542 0.8282655308842659 637002 [0.0001, 0.0001] 25062.508491277695\n",
      "638000 0.8716309070587158 0.826023534834385 638002 [0.0001, 0.0001] 25101.972755908966\n",
      "639000 0.8425253033638 0.8253451199531555 639002 [0.0001, 0.0001] 25139.00299859047\n",
      "640000 0.8093895316123962 0.826410988330841 640002 [0.0001, 0.0001] 25178.799478769302\n",
      "641000 0.8254512548446655 0.8259686554670334 641002 [0.0001, 0.0001] 25218.804851055145\n",
      "642000 0.7718862295150757 0.8246731854081154 642002 [0.0001, 0.0001] 25258.61202120781\n",
      "643000 0.7462279200553894 0.8240116668343545 643002 [0.0001, 0.0001] 25296.01499390602\n",
      "644000 0.7497561573982239 0.8246572630405427 644002 [0.0001, 0.0001] 25335.884404182434\n",
      "645000 0.7866433262825012 0.8241465404033661 645002 [0.0001, 0.0001] 25376.003674268723\n",
      "646000 0.7744807600975037 0.820603936612606 646002 [0.0001, 0.0001] 25416.031777858734\n",
      "647000 0.8302278518676758 0.8225604573488235 647002 [0.0001, 0.0001] 25456.164296150208\n",
      "648000 0.789174497127533 0.8226178594231606 648002 [0.0001, 0.0001] 25496.024881362915\n",
      "649000 0.8084244132041931 0.8209615059494972 649002 [0.0001, 0.0001] 25535.752472639084\n",
      "650000 0.8087390065193176 0.8228116839528083 650002 [0.0001, 0.0001] 25575.650004386902\n",
      "651000 0.7945175766944885 0.8208008088469505 651002 [0.0001, 0.0001] 25615.34768152237\n",
      "652000 0.8082252740859985 0.8220936854481697 652002 [0.0001, 0.0001] 25655.0239675045\n",
      "653000 0.7906856536865234 0.8191668573617935 653002 [0.0001, 0.0001] 25694.36151742935\n",
      "654000 0.837709367275238 0.8183056342601777 654002 [0.0001, 0.0001] 25734.036444664\n",
      "655000 0.878694474697113 0.8190320972204208 655002 [0.0001, 0.0001] 25773.71507382393\n",
      "656000 0.8622086048126221 0.8181962383985519 656002 [0.0001, 0.0001] 25812.554909944534\n",
      "657000 0.7672204375267029 0.8170870374441147 657002 [0.0001, 0.0001] 25851.91927933693\n",
      "658000 0.785643458366394 0.8183063752055169 658002 [0.0001, 0.0001] 25891.287186145782\n",
      "659000 0.8005381226539612 0.8171745757460595 659002 [0.0001, 0.0001] 25931.18671131134\n",
      "660000 0.7992511987686157 0.8166042393445969 660002 [0.0001, 0.0001] 25970.785299539566\n",
      "661000 0.8241109848022461 0.8159953710436821 661002 [0.0001, 0.0001] 26010.262610435486\n",
      "662000 0.8873063921928406 0.8142571309804917 662002 [0.0001, 0.0001] 26050.039265871048\n",
      "663000 0.7850078344345093 0.8147074919939041 663002 [0.0001, 0.0001] 26089.93550467491\n",
      "664000 0.8101542592048645 0.8142104427814484 664002 [0.0001, 0.0001] 26129.66317510605\n",
      "665000 0.8276539444923401 0.8150698428750038 665002 [0.0001, 0.0001] 26169.803020715714\n",
      "666000 0.8329886198043823 0.8134000786542892 666002 [0.0001, 0.0001] 26208.914733171463\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dataset \u001b[39m=\u001b[39m sample_dataset(i,batch\u001b[39m=\u001b[39mbatch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset[:], batch_size\u001b[39m=\u001b[39mbatch, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m train(dataloader, optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()    \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_len):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNLLLoss()(output[i], target_tensor[i])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m sum_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m seq_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m seq_tensor\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lr = 5e-4\n",
    "# optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr)\n",
    "batch=64\n",
    "s_time = time.time()\n",
    "plot_every = 1000\n",
    "avg_loss = 0\n",
    "for i in range(1000001):\n",
    "    dataset = sample_dataset(i,batch=batch)\n",
    "    dataloader = DataLoader(dataset[:], batch_size=batch, shuffle=True)\n",
    "    loss = train(dataloader, optimizer)\n",
    "    scheduler.step()    \n",
    "    avg_loss += loss\n",
    "    if i and i % plot_every == 0:\n",
    "        print(i, loss, avg_loss / plot_every, scheduler._step_count, scheduler.get_last_lr(),time.time() - s_time)\n",
    "        torch.save(gru, 'model/gru-09201.pth')\n",
    "        torch.save(s2h, 'model/s2h-09201.pth')\n",
    "        save_dict = {'epoch':i,\"optimizer\":optimizer.state_dict(),\"_step_count\":scheduler._step_count,\"last_epoch\":scheduler.last_epoch}\n",
    "        torch.save(save_dict,\"model/save_dict-09201.pth\")\n",
    "        if avg_loss / plot_every < 0.18:\n",
    "            print(i, avg_loss / plot_every)\n",
    "            break\n",
    "        avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2).to(device)\n",
    "def sample(size_data, seq_length, start_size=8):\n",
    "    gru.eval()\n",
    "    s2h.eval()\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        size_tensor = torch.tensor(size_data, dtype=torch.float).to(device)\n",
    "        hn = s2h(size_tensor)\n",
    "        output_seq = [start_size]\n",
    "        size = start_size\n",
    "        for _ in range(seq_length - 1):\n",
    "            input = inputTensor(np.array([[size]])).to(device)\n",
    "            input = input.float()\n",
    "            output, hn = gru(input, hn)\n",
    "            output = softmax(output)\n",
    "            p_size = output.detach().cpu().numpy().squeeze()\n",
    "            size = np.random.choice(n_size, p=p_size)\n",
    "            output_seq.append(size)\n",
    "        return output_seq\n",
    "\n",
    "def is_subarray(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "    for i in range(len(arr1) - len(arr2) + 1):\n",
    "        if np.array_equal(arr1[i:i+len(arr2)], arr2):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 6, 10, 13, 13, 8, 9, 6, 7, 4, 4, 11, 4, 7, 13] False\n",
      "[8, 11, 6, 8, 4, 10, 4, 7, 6, 7, 4, 6, 11, 4, 7, 11] False\n",
      "[8, 4, 11, 7, 4, 4, 11, 4, 6, 4, 8, 10, 11, 13, 4, 7] False\n",
      "[8, 8, 8, 4, 7, 10, 4, 8, 11, 9, 4, 11, 6, 4, 4, 9] False\n",
      "[8, 4, 13, 16, 7, 11, 4, 4, 4, 4, 7, 8, 7, 13, 4, 4] False\n",
      "[8, 8, 7, 4, 7, 4, 8, 8, 7, 6, 8, 10, 4, 4, 6, 9] False\n",
      "[8, 7, 10, 7, 13, 13, 4, 7, 10, 13, 10, 4, 8, 7, 10, 4] False\n",
      "[8, 4, 3, 6, 7, 4, 10, 13, 13, 8, 7, 7, 9, 7, 11, 9] False\n",
      "[8, 8, 6, 4, 4, 16, 6, 4, 4, 10, 7, 8, 4, 11, 13, 2] False\n",
      "[8, 6, 4, 4, 7, 10, 4, 7, 8, 7, 12, 4, 7, 9, 7, 5] False\n",
      "[8, 13, 6, 13, 4, 6, 10, 16, 6, 8, 11, 10, 13, 7, 13, 7] False\n",
      "[8, 11, 13, 8, 4, 4, 7, 4, 11, 13, 4, 6, 13, 6, 8, 11] False\n",
      "[8, 11, 13, 13, 11, 8, 8, 13, 4, 6, 13, 4, 8, 13, 11, 8] False\n",
      "[8, 6, 4, 6, 4, 4, 13, 13, 6, 10, 13, 8, 7, 4, 7, 4] False\n",
      "[8, 11, 10, 3, 6, 4, 8, 4, 4, 4, 13, 13, 13, 4, 11, 4] False\n",
      "[8, 9, 13, 6, 4, 13, 6, 13, 10, 7, 4, 7, 8, 4, 13, 8] False\n",
      "[8, 13, 13, 6, 8, 6, 11, 4, 4, 4, 8, 7, 13, 4, 9, 6] False\n",
      "[8, 8, 4, 13, 10, 4, 4, 13, 10, 13, 13, 10, 8, 7, 15, 4] False\n",
      "[8, 5, 7, 13, 6, 6, 4, 7, 8, 6, 4, 6, 8, 4, 13, 4] False\n",
      "[8, 11, 4, 8, 8, 7, 11, 8, 7, 13, 8, 4, 11, 13, 7, 4] False\n",
      "[8, 8, 13, 8, 6, 7, 7, 8, 7, 11, 13, 4, 10, 6, 10, 13] False\n",
      "[8, 4, 13, 10, 9, 8, 7, 13, 13, 13, 13, 6, 4, 8, 7, 6] False\n",
      "[8, 8, 13, 8, 4, 4, 13, 4, 4, 13, 7, 4, 13, 8, 6, 6] False\n",
      "[8, 4, 8, 4, 4, 8, 8, 4, 11, 10, 8, 7, 7, 8, 7, 11] False\n",
      "[8, 4, 11, 4, 13, 4, 8, 7, 11, 11, 4, 13, 8, 6, 4, 11] False\n",
      "[8, 7, 4, 8, 10, 8, 7, 7, 7, 4, 8, 13, 4, 4, 13, 7] False\n",
      "[8, 8, 4, 10, 7, 4, 1, 13, 10, 6, 13, 8, 6, 13, 4, 10] False\n",
      "[8, 8, 11, 6, 11, 8, 5, 4, 11, 4, 4, 16, 6, 4, 4, 11] False\n",
      "[8, 4, 9, 10, 4, 11, 4, 7, 8, 10, 13, 4, 13, 13, 11, 8] False\n",
      "[8, 4, 11, 11, 11, 13, 7, 11, 6, 13, 8, 8, 8, 13, 8, 4] False\n",
      "[8, 10, 10, 6, 7, 12, 3, 11, 4, 6, 11, 11, 11, 7, 6, 7] False\n",
      "[8, 7, 10, 13, 13, 4, 13, 7, 4, 4, 8, 11, 6, 8, 6, 4] False\n",
      "[8, 8, 7, 8, 6, 4, 6, 13, 16, 8, 13, 8, 10, 8, 6, 4] False\n",
      "[8, 4, 4, 8, 3, 11, 4, 4, 11, 13, 4, 8, 4, 9, 8, 6] False\n",
      "[8, 4, 11, 13, 4, 4, 4, 6, 6, 4, 10, 10, 13, 7, 8, 4] False\n",
      "[8, 10, 8, 8, 10, 9, 8, 8, 7, 7, 4, 7, 7, 4, 4, 8] False\n",
      "[8, 13, 6, 6, 11, 4, 9, 11, 7, 11, 4, 4, 10, 7, 8, 10] False\n",
      "[8, 8, 5, 13, 7, 11, 8, 6, 11, 4, 4, 13, 9, 13, 15, 7] False\n",
      "[8, 4, 11, 4, 4, 7, 7, 6, 7, 2, 8, 4, 16, 13, 6, 7] False\n",
      "[8, 6, 4, 4, 11, 4, 7, 4, 7, 8, 4, 11, 11, 13, 4, 13] False\n",
      "[8, 4, 9, 7, 2, 11, 11, 8, 3, 13, 7, 4, 4, 11, 8, 10] False\n",
      "[8, 4, 8, 6, 8, 13, 10, 7, 7, 7, 7, 4, 4, 4, 4, 7] False\n",
      "[8, 4, 8, 10, 11, 4, 4, 7, 4, 8, 8, 8, 13, 4, 7, 4] False\n",
      "[8, 4, 6, 13, 8, 4, 9, 6, 8, 4, 4, 4, 6, 4, 6, 8] False\n",
      "[8, 4, 8, 4, 11, 13, 2, 4, 4, 7, 13, 6, 6, 13, 8, 13] False\n",
      "[8, 6, 7, 4, 6, 11, 4, 7, 12, 8, 13, 13, 7, 11, 7, 10] False\n",
      "[8, 13, 11, 4, 10, 4, 10, 8, 4, 4, 13, 8, 4, 4, 10, 7] False\n",
      "[8, 13, 13, 4, 7, 8, 11, 7, 11, 8, 10, 4, 4, 4, 7, 7] False\n",
      "[8, 4, 6, 8, 8, 7, 8, 7, 4, 6, 10, 7, 11, 11, 7, 4] False\n",
      "[8, 10, 13, 6, 7, 11, 10, 9, 6, 4, 8, 11, 11, 13, 4, 15] False\n",
      "[8, 3, 9, 4, 8, 4, 9, 8, 7, 10, 4, 7, 11, 8, 13, 8] False\n",
      "[8, 7, 20, 4, 6, 7, 4, 13, 7, 13, 4, 4, 13, 4, 15, 6] False\n",
      "[8, 11, 8, 11, 4, 7, 4, 8, 6, 8, 7, 6, 10, 16, 8, 6] False\n",
      "[8, 7, 5, 7, 4, 4, 6, 8, 6, 4, 11, 7, 8, 4, 8, 4] False\n",
      "[8, 8, 7, 4, 11, 9, 10, 11, 11, 8, 7, 8, 8, 8, 6, 4] False\n",
      "[8, 4, 7, 4, 13, 6, 6, 13, 8, 4, 11, 7, 7, 11, 8, 11] False\n",
      "[8, 4, 7, 4, 11, 13, 4, 8, 11, 4, 8, 9, 13, 4, 7, 11] False\n",
      "[8, 7, 6, 7, 8, 11, 8, 4, 8, 17, 8, 8, 4, 8, 7, 7] False\n",
      "[8, 10, 8, 6, 8, 13, 4, 8, 7, 4, 11, 7, 10, 4, 10, 7] False\n",
      "[8, 13, 4, 8, 11, 6, 11, 8, 4, 8, 11, 11, 6, 8, 7, 8] False\n",
      "[8, 4, 10, 10, 6, 6, 11, 13, 10, 4, 7, 4, 13, 11, 6, 8] False\n",
      "[8, 6, 11, 4, 8, 4, 7, 10, 4, 13, 4, 8, 8, 8, 7, 8] False\n",
      "[8, 7, 4, 8, 11, 10, 4, 13, 11, 8, 8, 11, 9, 10, 4, 4] False\n",
      "[8, 11, 4, 7, 13, 10, 4, 7, 8, 4, 13, 10, 6, 4, 4, 7] False\n",
      "[8, 6, 6, 4, 7, 7, 4, 4, 9, 5, 11, 13, 4, 6, 9, 8] False\n",
      "[8, 6, 4, 8, 7, 8, 13, 7, 4, 4, 2, 4, 7, 11, 10, 4] False\n",
      "[8, 2, 7, 10, 11, 7, 4, 13, 8, 10, 7, 13, 8, 8, 16, 10] False\n",
      "[8, 13, 4, 7, 4, 8, 13, 7, 13, 7, 7, 4, 7, 13, 13, 4] False\n",
      "[8, 4, 10, 4, 6, 8, 8, 11, 13, 7, 11, 7, 4, 13, 6, 13] False\n",
      "[8, 9, 6, 4, 7, 8, 8, 4, 13, 7, 11, 15, 7, 15, 13, 11] False\n",
      "[8, 8, 9, 11, 13, 16, 7, 4, 16, 10, 8, 10, 13, 9, 7, 4] False\n",
      "[8, 10, 7, 4, 11, 4, 4, 4, 11, 7, 4, 4, 4, 6, 13, 13] False\n",
      "[8, 4, 6, 7, 6, 13, 8, 7, 4, 11, 8, 11, 7, 13, 4, 13] False\n",
      "[8, 4, 7, 11, 4, 7, 6, 7, 4, 8, 6, 13, 8, 4, 6, 11] False\n",
      "[8, 6, 6, 10, 6, 15, 8, 11, 13, 13, 13, 4, 13, 8, 13, 8] False\n",
      "[8, 8, 13, 7, 7, 4, 4, 13, 13, 8, 7, 13, 4, 11, 7, 11] False\n",
      "[8, 10, 8, 4, 8, 11, 7, 7, 13, 7, 10, 7, 4, 7, 13, 11] False\n",
      "[8, 8, 4, 8, 2, 8, 11, 6, 9, 10, 8, 10, 4, 13, 4, 4] False\n",
      "[8, 4, 8, 15, 4, 9, 4, 7, 10, 4, 8, 13, 7, 4, 11, 8] False\n",
      "[8, 8, 8, 8, 4, 11, 8, 10, 7, 8, 10, 8, 8, 6, 11, 7] False\n",
      "[8, 13, 9, 9, 11, 10, 4, 13, 6, 4, 11, 13, 4, 7, 4, 6] False\n",
      "[8, 8, 4, 2, 12, 8, 7, 4, 8, 7, 4, 4, 4, 11, 8, 13] False\n",
      "[8, 6, 8, 4, 7, 4, 13, 11, 4, 8, 13, 4, 8, 13, 13, 7] False\n",
      "[8, 6, 7, 8, 11, 8, 6, 7, 11, 11, 8, 8, 7, 4, 7, 13] False\n",
      "[8, 13, 13, 11, 11, 7, 13, 13, 8, 4, 6, 10, 7, 4, 6, 13] False\n",
      "[8, 7, 11, 7, 4, 6, 4, 7, 8, 13, 8, 10, 10, 8, 4, 4] False\n",
      "[8, 6, 6, 8, 16, 13, 7, 11, 11, 10, 8, 4, 4, 4, 8, 8] False\n",
      "[8, 8, 8, 9, 11, 4, 6, 7, 4, 8, 7, 4, 6, 6, 4, 11] False\n",
      "[8, 2, 13, 4, 13, 6, 10, 7, 7, 4, 8, 7, 13, 11, 8, 8] False\n",
      "[8, 9, 11, 11, 4, 4, 4, 11, 4, 6, 10, 11, 4, 11, 9, 13] False\n",
      "[8, 4, 11, 10, 4, 6, 8, 8, 13, 4, 7, 11, 6, 4, 7, 4] False\n",
      "[8, 13, 10, 4, 6, 4, 13, 8, 1, 2, 4, 11, 4, 11, 6, 1] False\n",
      "[8, 4, 11, 6, 4, 6, 7, 8, 4, 13, 4, 6, 3, 7, 8, 9] False\n",
      "[8, 6, 4, 10, 7, 6, 4, 11, 13, 7, 6, 4, 6, 6, 8, 8] False\n",
      "[8, 7, 10, 4, 7, 8, 4, 4, 7, 4, 7, 13, 13, 4, 13, 10] False\n",
      "[8, 6, 10, 6, 10, 7, 11, 16, 7, 7, 13, 13, 11, 8, 7, 4] False\n",
      "[8, 4, 6, 10, 7, 10, 13, 6, 8, 4, 4, 11, 13, 10, 8, 6] False\n",
      "[8, 8, 4, 8, 8, 7, 8, 4, 13, 6, 11, 4, 4, 8, 8, 13] False\n",
      "[8, 7, 6, 4, 4, 4, 11, 8, 6, 6, 13, 15, 4, 8, 15, 13] False\n",
      "[8, 8, 6, 6, 13, 8, 4, 6, 4, 6, 5, 4, 4, 13, 4, 13] False\n"
     ]
    }
   ],
   "source": [
    "pair = 0\n",
    "start_size = 8\n",
    "for i in range(100):\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "    a = sample(sizedata[pair], 16, start_size)\n",
    "    print(a, is_subarray(size_index, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "s2s_pair, size_trans = get_trans(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 0.06711409395973156 172\n"
     ]
    }
   ],
   "source": [
    "plf_dict={}\n",
    "# print(size_trans[0])\n",
    "# plf_dict[str(sizedata[0])]=size_trans[0]\n",
    "\n",
    "# print(sizedata[0])\n",
    "minp=100\n",
    "maxp=0\n",
    "ans=0\n",
    "for i in range(1000):\n",
    "    for j in range(i):\n",
    "        if i==j:\n",
    "            continue\n",
    "        minp=min(np.sum(np.abs(sizedata[i]-sizedata[j])),minp)\n",
    "        maxp=max(maxp,np.sum(np.abs(sizedata[i]-sizedata[j])))\n",
    "        if(np.sum(np.square(sizedata[i]-sizedata[j]))<0.001):\n",
    "            ans+=1\n",
    "print(maxp,minp,ans)\n",
    "# for i in range(1000):\n",
    "#     try:\n",
    "#         plf_dict[str(sizedata[i])]\n",
    "#     # if sizedata[i] in plf_dict.keys():\n",
    "#         temp = plf_dict[str(sizedata[i])]\n",
    "#         temp += size_trans[i]\n",
    "#         temp/=2\n",
    "#         plf_dict[str(sizedata[i])]=temp\n",
    "#         print(\"1\\n\")\n",
    "#     except:\n",
    "#         plf_dict[str(sizedata[i])]=size_trans[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 990/8192 [54:18<6:35:01,  3.29s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m size_seq \u001b[39m=\u001b[39m [start_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(size_seq) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     new_size \u001b[39m=\u001b[39m sample(size_data, seq_len, start_size\u001b[39m=\u001b[39;49mstart_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     size_seq \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(new_size[:])\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m inputTensor(np\u001b[39m.\u001b[39marray([[size]]))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output, hn \u001b[39m=\u001b[39m gru(\u001b[39minput\u001b[39;49m, hn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m softmax(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m p_size \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m3\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     out_\u001b[39m=\u001b[39mout\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m out \u001b[39m=\u001b[39m o(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m3\u001b[39m\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m out_\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1124\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1125\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1126\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "encore_seq = np.zeros((pairs, 1000))\n",
    "he_seq = np.zeros((pairs, 1000))\n",
    "\n",
    "for pair in tqdm(range(pairs)):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    size_seq = []\n",
    "    while len(size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq.append(size)\n",
    "    size_seq = np.array(size_seq)[0:1000]\n",
    "    he_seq[pair] = size_seq\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq = [start_size]\n",
    "        while len(size_seq) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq += list(new_size[:])\n",
    "                # start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "            start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        \n",
    "        \n",
    "        size_seq = np.array(size_seq)\n",
    "        values, counts = np.unique(size_seq, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq[:-1] * n_size + size_seq[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            # print(pair, seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "            break\n",
    "\n",
    "    encore_seq[pair] = size_seq[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = pairdata[freqpairs[pair]]['size_index'].values\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        grams[i][pair][values] = counts\n",
    "    grams[i] /= grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "he_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    he_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = he_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        he_grams[i][pair][values] = counts\n",
    "    he_grams[i] /= he_grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "encore_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    encore_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = encore_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        encore_grams[i][pair][values] = counts\n",
    "    encore_grams[i] /= encore_grams[i].sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_jsds, encore_jsds = {}, {}\n",
    "for i in range(2, 5):\n",
    "    he_jsds[i] = []    \n",
    "    encore_jsds[i] = []    \n",
    "    for pair in range(pairs):\n",
    "        he_jsds[i].append(JSD(grams[i][pair], he_grams[i][pair]))\n",
    "        encore_jsds[i].append(JSD(grams[i][pair], encore_grams[i][pair]))\n",
    "    he_jsds[i] = np.array(he_jsds[i])\n",
    "    encore_jsds[i] = np.array(encore_jsds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(2, 5):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.subplots_adjust(left=0.18, top=0.95, bottom=0.24, right=0.98)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    values, bins = np.histogram(encore_jsds[i], bins=np.arange(0, np.max(encore_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='CornFlowerBlue', label='Encore-Sequential')\n",
    "    values, bins = np.histogram(he_jsds[i], bins=np.arange(0, np.max(he_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='IndianRed', label='Common Practice')\n",
    "    plt.ylim(0, 1.05)\n",
    "    # plt.legend(fontsize=20, frameon=False, loc=(0.45, 0.2))\n",
    "    plt.ylabel('CDF', fontsize=20)\n",
    "    plt.xlabel('JSD', fontsize=20)\n",
    "    plt.grid(linestyle='-.')\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    if i == 2:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.125, 0.84, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    elif i == 3:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.22, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    else:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.3, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    plt.legend(fontsize=20, frameon=False, loc=(0.185, -0.025), handletextpad=0.5)\n",
    "\n",
    "    plt.savefig('figure/{i}-gram-jsd.pdf'.format(i=i), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.003780834346872495 0.03191653927373678 0.071636531638431\n",
      "1 0.004638559763069713 0.07615157309426068 0.086361499954088\n",
      "2 0.004743510072321645 0.052714327769370774 0.09041966129037701\n",
      "3 0.003910066967083189 0.046387686302565165 0.08037825775341918\n",
      "4 0.004251519270877972 0.07344276269154196 0.11091550727250109\n",
      "5 0.006960660467828972 0.0332885150920444 0.05843249684209055\n",
      "6 0.004442947659530791 0.08355688074283867 0.12483076363187569\n",
      "7 0.004954549728187721 0.06519295956781357 0.13241771341810435\n",
      "8 0.004871947618424683 0.0842010342363523 0.11672103015604808\n",
      "9 0.008770857246823912 0.08359442603152073 0.09226857847679462\n",
      "10 0.004622773660494375 0.06622446884094543 0.10709661219972966\n",
      "11 0.012201826432418421 0.09490307582004151 0.12403968853068947\n",
      "12 0.007232087051021963 0.07758210507143679 0.09547661518733022\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m size_seq_gen \u001b[39m=\u001b[39m [start_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(size_seq_gen) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     new_size \u001b[39m=\u001b[39m sample(size_data, seq_len, start_size\u001b[39m=\u001b[39;49mstart_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     size_seq_gen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(new_size[\u001b[39m1\u001b[39m:])\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m inputTensor(np\u001b[39m.\u001b[39marray([[size]]))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output, hn \u001b[39m=\u001b[39m gru(\u001b[39minput\u001b[39;49m, hn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m softmax(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m p_size \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m2\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     out_\u001b[39m=\u001b[39mout\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m out \u001b[39m=\u001b[39m o(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m2\u001b[39m\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m out_\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_jsds, he_jsds,min_jsds = [], [],[]\n",
    "for pair in range(500):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = [start_size]\n",
    "        while len(size_seq_gen) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq_gen += list(new_size[1:])\n",
    "            start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "                #     start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = np.array(size_seq_gen)\n",
    "        values, counts = np.unique(size_seq_gen, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        # print(seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            break\n",
    "\n",
    "    rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "    values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "    rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "    rnn_s2s_pair[values] = counts\n",
    "    rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "\n",
    "    he_size_seq = []\n",
    "    while len(he_size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        he_size_seq.append(size)\n",
    "    he_size_seq = np.array(he_size_seq)\n",
    "\n",
    "    he_s2s_pair = [he_size_seq[:-1] * n_size + he_size_seq[1:]]  \n",
    "    values, counts = np.unique(he_s2s_pair, return_counts=True)\n",
    "    he_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    he_s2s_pair[values] = counts\n",
    "    he_s2s_pair /= he_s2s_pair.sum()\n",
    "    \n",
    "    min_size_seq = []\n",
    "    min_size_seq.append(np.random.choice(n_size, p=size_data))\n",
    "    while len(min_size_seq) < 1000:\n",
    "        min_size_seq.append(np.random.choice(n_size, p=size_trans[pair][min_size_seq[-1]]))\n",
    "    min_size_seq = np.array(min_size_seq)\n",
    "        \n",
    "    min_s2s_pair = [min_size_seq[:-1] * n_size + min_size_seq[1:]]  \n",
    "    values, counts = np.unique(min_s2s_pair, return_counts=True)\n",
    "    min_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    min_s2s_pair[values] = counts\n",
    "    min_s2s_pair /= min_s2s_pair.sum()\n",
    "\n",
    "    print(pair, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]), JSD(he_s2s_pair, s2s_pair[pair]))\n",
    "    rnn_jsds.append(JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "    min_jsds.append(JSD(min_s2s_pair, s2s_pair[pair]))\n",
    "    he_jsds.append(JSD(he_s2s_pair, s2s_pair[pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.05)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values, bins = np.histogram(rnn_jsds, bins=np.arange(0, np.max(rnn_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(he_jsds, bins=np.arange(0, np.max(he_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(min_jsds, bins=np.arange(0, np.max(min_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "plt.ylim(0, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(gru, 'models/gru-0504.pth')\n",
    "# torch.save(s2h, 'models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeDecoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dims, latent_dim):\n",
    "        super(SizeDecoder, self).__init__()\n",
    "        self.decoder = torch.nn.ModuleList()\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_dim, out_features=h_dim,),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            in_dim = h_dim\n",
    "        self.output = nn.Linear(hidden_dims[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        for module in self.decoder:\n",
    "            x = module(x)\n",
    "        result = self.output(x)\n",
    "        result = F.softmax(result, dim=1)\n",
    "        return result\n",
    "    \n",
    "decoder = torch.load('models/size-decoder-0425.pth')\n",
    "gru = torch.load('models/gru-0504.pth')\n",
    "s2h = torch.load('models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "def sample_noisy_dataset(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = []\n",
    "    for i in tqdm(range(n)):\n",
    "        latent_dim = 32\n",
    "        z = torch.randn((1, latent_dim)).to(device)\n",
    "        size = decoder(z)\n",
    "        size = size.squeeze().detach().to('cpu').numpy()\n",
    "        size[size < 1e-3] = 0\n",
    "        size /= size.sum()\n",
    "\n",
    "        dis = []\n",
    "        for j in range(1000):\n",
    "            loss = JSD(size, sizedata[j])\n",
    "            dis.append(loss)\n",
    "\n",
    "        pair = np.argmin(dis)\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size, target_set[pair][ran_index]])\n",
    "        \n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
