{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, Tensor\n",
    "from typing import List\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from utils.dataset import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "pairs = 8192\n",
    "pairdata, freqpairs, n_size, n_interval = get_fb_data(pairs)\n",
    "sizedata = get_data(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_set = defaultdict(list)\n",
    "target_set = defaultdict(list)\n",
    "size_set = {}\n",
    "seq_len = 16\n",
    "\n",
    "for pair in range(pairs):\n",
    "    size_index = pairdata[freqpairs[pair]].size_index.values\n",
    "    target_index = np.concatenate((size_index[1:], size_index[0:1]))\n",
    "    for i in range(len(size_index) - seq_len):\n",
    "        seq_set[pair].append(size_index[i:i+seq_len])\n",
    "        target_set[pair].append(target_index[i:i+seq_len])\n",
    "        size_set[pair] = sizedata[pair]\n",
    "    seq_set[pair] = np.array(seq_set[pair])\n",
    "    target_set[pair] = np.array(target_set[pair])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(seed, batch=32):\n",
    "    np.random.seed(seed)\n",
    "    dataset = []\n",
    "    ps = [np.random.randint(pairs) for i in range(batch)]\n",
    "    for pair in ps:\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size_set[pair], target_set[pair][ran_index]])\n",
    "    return dataset\n",
    "\n",
    "def inputTensor(lines):\n",
    "    tensor = torch.zeros(lines.shape[1], lines.shape[0], n_size, dtype=torch.long)\n",
    "    for line in range(lines.shape[0]):\n",
    "        for i in range(lines.shape[1]):\n",
    "            size = lines[line][i]\n",
    "            tensor[i][line][size] = 1\n",
    "    return tensor\n",
    "\n",
    "dataset = sample_dataset(0)\n",
    "dataloader = DataLoader(dataset[:32], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeToHidden(nn.Module):\n",
    "    def __init__(self, input_size,  n_deep, hidden_size, n_layer):\n",
    "        super(SizeToHidden, self).__init__()\n",
    "        self.lins = nn.ModuleList()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_net = nn.Sequential(\n",
    "                    nn.Linear(input_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "        for _ in range(n_deep):\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.lins.append(\n",
    "                nn.Sequential(\n",
    "                    nn.LayerNorm(hidden_size))\n",
    "            )\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, out_features=hidden_size * n_layer)\n",
    "\n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        x = self.in_net(x)\n",
    "        i = 0\n",
    "        for lin in self.lins:\n",
    "            if i % 3 == 0:\n",
    "                x_ = x\n",
    "            x = lin(x)\n",
    "            if i % 3 == 1:\n",
    "                x = x + x_\n",
    "            i = (i+1)%3\n",
    "        x = self.output(x)\n",
    "        x = x.view(-1, self.n_layer, self.hidden_size)\n",
    "        x = x.permute(1, 0, 2).contiguous()\n",
    "        # x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layer, n_deep):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layer)\n",
    "        \n",
    "        self.o2o = nn.Linear(hidden_size+n_size, hidden_size)\n",
    "        self.ots = nn.ModuleList()\n",
    "        for _ in range(n_deep):\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            self.ots.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, out_features=hidden_size),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            # self.ots.append(\n",
    "            #     nn.Sequential(\n",
    "            #         nn.LayerNorm(hidden_size))\n",
    "            # )\n",
    "        self.h2o = nn.Linear(hidden_size, n_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.norm_1 = nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        out = self.norm(out)\n",
    "        i=0\n",
    "        for o in self.ots:\n",
    "            if i%2==0:\n",
    "                out_=out\n",
    "            out = o(out)\n",
    "            if i%2==1:\n",
    "                out = out + out_\n",
    "            i = (i+1)%2\n",
    "        out = self.norm_1(out)\n",
    "        out = self.h2o(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        out = self.softmax(out)\n",
    "        # print(out.shape)torch.Size([8, 9000, 30])\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "gru = GRU(n_size, hidden_size, 4, 48).to(device)\n",
    "s2h = SizeToHidden(n_size, 2, hidden_size, 4).to(device)\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8e5,16e5,24e5,32e5],gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size = 128\n",
    "# gru = GRU(n_size, hidden_size, 1).to(device)\n",
    "# s2h = SizeToHidden(n_size, [64, 128], hidden_size, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31073822, 2120192, 33194014)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total parameters and trainable parameters of gru and s2h\n",
    "def get_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "get_params(gru)[0], get_params(s2h)[0], get_params(gru)[0] + get_params(s2h)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509618"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_flow = 0\n",
    "for i in range(pairs):\n",
    "    sum_flow += len(pairdata[freqpairs[i]])\n",
    "sum_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.882237777777775"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_params(gru)[0] + get_params(s2h)[0]) / 900000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = 'final'\n",
    "# gru = torch.load('model/{date}/gru.pth'.format(date=date))\n",
    "# s2h = torch.load('model/{date}/s2h.pth'.format(date=date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181002 181001\n"
     ]
    }
   ],
   "source": [
    "# gru=torch.load('model/gru-09201.pth')\n",
    "# s2h=torch.load('model/s2h-09201.pth')\n",
    "# save_dict = torch.load(\"model/save_dict-09201.pth\")\n",
    "# optimizer.load_state_dict(save_dict['optimizer'])\n",
    "# scheduler._step_count = save_dict[\"_step_count\"]\n",
    "# scheduler.last_epoch = save_dict[\"last_epoch\"]\n",
    "# print(save_dict[\"_step_count\"],save_dict[\"last_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, optimizer):\n",
    "    gru.train()\n",
    "    s2h.train()\n",
    "    sum_loss = 0\n",
    "    for seq_tensor, size_tensor, target_tensor in dataloader:\n",
    "        seq_tensor = inputTensor(seq_tensor).float().to(device)\n",
    "        size_tensor = size_tensor.float().to(device)\n",
    "        target_tensor = target_tensor.T.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, hn = gru(seq_tensor, s2h(size_tensor))\n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            loss += nn.NLLLoss()(output[i], target_tensor[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss.item() / seq_tensor.shape[0] * seq_tensor.shape[1]\n",
    "    return sum_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总参数数量和：31073822\n",
      "总参数数量和：2120192\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = gru\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "model = s2h\n",
    "params = list(model.parameters())\n",
    "k = 0\n",
    "for i in params:\n",
    "    l = 1\n",
    "    # print(\"该层的结构：\" + str(list(i.size())))\n",
    "    for j in i.size():\n",
    "        l *= j\n",
    "    # print(\"该层参数和：\" + str(l))\n",
    "    k = k + l\n",
    "print(\"总参数数量和：\" + str(k))\n",
    "print(optimizer.state_dict()['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.6817637085914612 0.682302148103714 182003 [0.0001, 0.0001] 29.098113536834717\n",
      "2000 0.6567378044128418 0.6827034376263619 183003 [0.0001, 0.0001] 59.09012770652771\n",
      "3000 0.6683963537216187 0.6798102684020996 184003 [0.0001, 0.0001] 88.62839245796204\n",
      "4000 0.7054764628410339 0.6818298488855362 185003 [0.0001, 0.0001] 118.31920528411865\n",
      "5000 0.6522870659828186 0.6818624102473259 186003 [0.0001, 0.0001] 148.3862760066986\n",
      "6000 0.7019555568695068 0.6823114268779754 187003 [0.0001, 0.0001] 176.037113904953\n",
      "7000 0.6188706755638123 0.6809693150520325 188003 [0.0001, 0.0001] 204.75225973129272\n",
      "8000 0.6131671667098999 0.6789812008738518 189003 [0.0001, 0.0001] 233.04270124435425\n",
      "9000 0.6369392275810242 0.6802905334830284 190003 [0.0001, 0.0001] 262.3659327030182\n",
      "10000 0.6571334600448608 0.6812054442167282 191003 [0.0001, 0.0001] 292.3304121494293\n",
      "11000 0.6647449731826782 0.680234530210495 192003 [0.0001, 0.0001] 322.3098771572113\n",
      "12000 0.6507442593574524 0.6802505760788917 193003 [0.0001, 0.0001] 352.40630078315735\n",
      "13000 0.6428388357162476 0.6812228537201881 194003 [0.0001, 0.0001] 382.134614944458\n",
      "14000 0.7433409690856934 0.6826044919490815 195003 [0.0001, 0.0001] 412.0538456439972\n",
      "15000 0.6890245676040649 0.6812652933001518 196003 [0.0001, 0.0001] 442.05440521240234\n",
      "16000 0.6586526036262512 0.680272090613842 197003 [0.0001, 0.0001] 472.0608549118042\n",
      "17000 0.7142931222915649 0.6799753813147544 198003 [0.0001, 0.0001] 502.1419429779053\n",
      "18000 0.6632623672485352 0.6798910967111588 199003 [0.0001, 0.0001] 532.2460989952087\n",
      "19000 0.7054866552352905 0.682509380698204 200003 [0.0001, 0.0001] 562.2181231975555\n",
      "20000 0.6974146962165833 0.6812780773043633 201003 [0.0001, 0.0001] 592.201611995697\n",
      "21000 0.6633225679397583 0.6792143486142158 202003 [0.0001, 0.0001] 621.9975066184998\n",
      "22000 0.6575902700424194 0.68089199000597 203003 [0.0001, 0.0001] 650.5914239883423\n",
      "23000 0.716152548789978 0.6796989412903786 204003 [0.0001, 0.0001] 677.9817154407501\n",
      "24000 0.701504647731781 0.6822033143043518 205003 [0.0001, 0.0001] 705.9029223918915\n",
      "25000 0.6984854340553284 0.6820733597278595 206003 [0.0001, 0.0001] 733.7955164909363\n",
      "26000 0.6796749234199524 0.6785917981863022 207003 [0.0001, 0.0001] 761.8890268802643\n",
      "27000 0.6860988736152649 0.680481026828289 208003 [0.0001, 0.0001] 791.562558889389\n",
      "28000 0.6620073318481445 0.6803723464012146 209003 [0.0001, 0.0001] 820.6422853469849\n",
      "29000 0.7617114186286926 0.6819800574779511 210003 [0.0001, 0.0001] 849.0328896045685\n",
      "30000 0.6423177123069763 0.6815812919139862 211003 [0.0001, 0.0001] 876.5153472423553\n",
      "31000 0.6941330432891846 0.6815488084554672 212003 [0.0001, 0.0001] 906.0259435176849\n",
      "32000 0.7415623664855957 0.6802846943736076 213003 [0.0001, 0.0001] 935.9754514694214\n",
      "33000 0.6894667744636536 0.6803660871982574 214003 [0.0001, 0.0001] 966.0382452011108\n",
      "34000 0.7027438879013062 0.6795514550805092 215003 [0.0001, 0.0001] 996.1982946395874\n",
      "35000 0.6498786807060242 0.6810989813804627 216003 [0.0001, 0.0001] 1026.35835647583\n",
      "36000 0.6986880898475647 0.6804078014492989 217003 [0.0001, 0.0001] 1055.2784662246704\n",
      "37000 0.6963198184967041 0.6796337924599648 218003 [0.0001, 0.0001] 1085.2935445308685\n",
      "38000 0.6820226907730103 0.680989170730114 219003 [0.0001, 0.0001] 1115.3538846969604\n",
      "39000 0.7025889754295349 0.6803853220939636 220003 [0.0001, 0.0001] 1145.0371723175049\n",
      "40000 0.6782584190368652 0.6791910763978958 221003 [0.0001, 0.0001] 1175.0708355903625\n",
      "41000 0.6451892256736755 0.6807854557037354 222003 [0.0001, 0.0001] 1204.8019371032715\n",
      "42000 0.667340874671936 0.6800063059329987 223003 [0.0001, 0.0001] 1234.5724294185638\n",
      "43000 0.653976559638977 0.6795429581999779 224003 [0.0001, 0.0001] 1264.7423396110535\n",
      "44000 0.7053194046020508 0.680363340139389 225003 [0.0001, 0.0001] 1294.8413672447205\n",
      "45000 0.693748414516449 0.6789232285618783 226003 [0.0001, 0.0001] 1324.8587262630463\n",
      "46000 0.6651332378387451 0.6779957988262176 227003 [0.0001, 0.0001] 1353.8937556743622\n",
      "47000 0.6813952922821045 0.6769646593928337 228003 [0.0001, 0.0001] 1382.6768341064453\n",
      "48000 0.6799156665802002 0.6797070462107658 229003 [0.0001, 0.0001] 1411.0311682224274\n",
      "49000 0.7096900343894958 0.6776093748807908 230003 [0.0001, 0.0001] 1439.9249341487885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m torch\u001b[39m.\u001b[39msave(s2h, \u001b[39m'\u001b[39m\u001b[39mmodel/s2h-0920.pth\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m save_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m:i,\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m:optimizer\u001b[39m.\u001b[39mstate_dict(),\u001b[39m\"\u001b[39m\u001b[39m_step_count\u001b[39m\u001b[39m\"\u001b[39m:scheduler\u001b[39m.\u001b[39m_step_count,\u001b[39m\"\u001b[39m\u001b[39mlast_epoch\u001b[39m\u001b[39m\"\u001b[39m:scheduler\u001b[39m.\u001b[39mlast_epoch}\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(save_dict,\u001b[39m\"\u001b[39;49m\u001b[39mmodel/save_dict-0920.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m avg_loss \u001b[39m/\u001b[39m plot_every \u001b[39m<\u001b[39m \u001b[39m0.18\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(i, avg_loss \u001b[39m/\u001b[39m plot_every)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/serialization.py:214\u001b[0m, in \u001b[0;36m_open_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lr = 5e-4\n",
    "# optimizer = torch.optim.Adam([{'params': gru.parameters()}, {'params': s2h.parameters()}], lr=lr)\n",
    "batch=64\n",
    "s_time = time.time()\n",
    "plot_every = 1000\n",
    "avg_loss = 0\n",
    "for i in range(1000001):\n",
    "    dataset = sample_dataset(i,batch=batch)\n",
    "    dataloader = DataLoader(dataset[:], batch_size=batch, shuffle=True)\n",
    "    loss = train(dataloader, optimizer)\n",
    "    scheduler.step()    \n",
    "    avg_loss += loss\n",
    "    if i and i % plot_every == 0:\n",
    "        print(i, loss, avg_loss / plot_every, scheduler._step_count, scheduler.get_last_lr(),time.time() - s_time)\n",
    "        torch.save(gru, 'model/gru-09201.pth')\n",
    "        torch.save(s2h, 'model/s2h-09201.pth')\n",
    "        save_dict = {'epoch':i,\"optimizer\":optimizer.state_dict(),\"_step_count\":scheduler._step_count,\"last_epoch\":scheduler.last_epoch}\n",
    "        torch.save(save_dict,\"model/save_dict-09201.pth\")\n",
    "        if avg_loss / plot_every < 0.18:\n",
    "            print(i, avg_loss / plot_every)\n",
    "            break\n",
    "        avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2).to(device)\n",
    "def sample(size_data, seq_length, start_size=8):\n",
    "    gru.eval()\n",
    "    s2h.eval()\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        size_tensor = torch.tensor(size_data, dtype=torch.float).to(device)\n",
    "        hn = s2h(size_tensor)\n",
    "        output_seq = [start_size]\n",
    "        size = start_size\n",
    "        for _ in range(seq_length - 1):\n",
    "            input = inputTensor(np.array([[size]])).to(device)\n",
    "            input = input.float()\n",
    "            output, hn = gru(input, hn)\n",
    "            output = softmax(output)\n",
    "            p_size = output.detach().cpu().numpy().squeeze()\n",
    "            size = np.random.choice(n_size, p=p_size)\n",
    "            output_seq.append(size)\n",
    "        return output_seq\n",
    "\n",
    "def is_subarray(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "    for i in range(len(arr1) - len(arr2) + 1):\n",
    "        if np.array_equal(arr1[i:i+len(arr2)], arr2):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 6, 10, 13, 13, 8, 9, 6, 7, 4, 4, 11, 4, 7, 13] False\n",
      "[8, 11, 6, 8, 4, 10, 4, 7, 6, 7, 4, 6, 11, 4, 7, 11] False\n",
      "[8, 4, 11, 7, 4, 4, 11, 4, 6, 4, 8, 10, 11, 13, 4, 7] False\n",
      "[8, 8, 8, 4, 7, 10, 4, 8, 11, 9, 4, 11, 6, 4, 4, 9] False\n",
      "[8, 4, 13, 16, 7, 11, 4, 4, 4, 4, 7, 8, 7, 13, 4, 4] False\n",
      "[8, 8, 7, 4, 7, 4, 8, 8, 7, 6, 8, 10, 4, 4, 6, 9] False\n",
      "[8, 7, 10, 7, 13, 13, 4, 7, 10, 13, 10, 4, 8, 7, 10, 4] False\n",
      "[8, 4, 3, 6, 7, 4, 10, 13, 13, 8, 7, 7, 9, 7, 11, 9] False\n",
      "[8, 8, 6, 4, 4, 16, 6, 4, 4, 10, 7, 8, 4, 11, 13, 2] False\n",
      "[8, 6, 4, 4, 7, 10, 4, 7, 8, 7, 12, 4, 7, 9, 7, 5] False\n",
      "[8, 13, 6, 13, 4, 6, 10, 16, 6, 8, 11, 10, 13, 7, 13, 7] False\n",
      "[8, 11, 13, 8, 4, 4, 7, 4, 11, 13, 4, 6, 13, 6, 8, 11] False\n",
      "[8, 11, 13, 13, 11, 8, 8, 13, 4, 6, 13, 4, 8, 13, 11, 8] False\n",
      "[8, 6, 4, 6, 4, 4, 13, 13, 6, 10, 13, 8, 7, 4, 7, 4] False\n",
      "[8, 11, 10, 3, 6, 4, 8, 4, 4, 4, 13, 13, 13, 4, 11, 4] False\n",
      "[8, 9, 13, 6, 4, 13, 6, 13, 10, 7, 4, 7, 8, 4, 13, 8] False\n",
      "[8, 13, 13, 6, 8, 6, 11, 4, 4, 4, 8, 7, 13, 4, 9, 6] False\n",
      "[8, 8, 4, 13, 10, 4, 4, 13, 10, 13, 13, 10, 8, 7, 15, 4] False\n",
      "[8, 5, 7, 13, 6, 6, 4, 7, 8, 6, 4, 6, 8, 4, 13, 4] False\n",
      "[8, 11, 4, 8, 8, 7, 11, 8, 7, 13, 8, 4, 11, 13, 7, 4] False\n",
      "[8, 8, 13, 8, 6, 7, 7, 8, 7, 11, 13, 4, 10, 6, 10, 13] False\n",
      "[8, 4, 13, 10, 9, 8, 7, 13, 13, 13, 13, 6, 4, 8, 7, 6] False\n",
      "[8, 8, 13, 8, 4, 4, 13, 4, 4, 13, 7, 4, 13, 8, 6, 6] False\n",
      "[8, 4, 8, 4, 4, 8, 8, 4, 11, 10, 8, 7, 7, 8, 7, 11] False\n",
      "[8, 4, 11, 4, 13, 4, 8, 7, 11, 11, 4, 13, 8, 6, 4, 11] False\n",
      "[8, 7, 4, 8, 10, 8, 7, 7, 7, 4, 8, 13, 4, 4, 13, 7] False\n",
      "[8, 8, 4, 10, 7, 4, 1, 13, 10, 6, 13, 8, 6, 13, 4, 10] False\n",
      "[8, 8, 11, 6, 11, 8, 5, 4, 11, 4, 4, 16, 6, 4, 4, 11] False\n",
      "[8, 4, 9, 10, 4, 11, 4, 7, 8, 10, 13, 4, 13, 13, 11, 8] False\n",
      "[8, 4, 11, 11, 11, 13, 7, 11, 6, 13, 8, 8, 8, 13, 8, 4] False\n",
      "[8, 10, 10, 6, 7, 12, 3, 11, 4, 6, 11, 11, 11, 7, 6, 7] False\n",
      "[8, 7, 10, 13, 13, 4, 13, 7, 4, 4, 8, 11, 6, 8, 6, 4] False\n",
      "[8, 8, 7, 8, 6, 4, 6, 13, 16, 8, 13, 8, 10, 8, 6, 4] False\n",
      "[8, 4, 4, 8, 3, 11, 4, 4, 11, 13, 4, 8, 4, 9, 8, 6] False\n",
      "[8, 4, 11, 13, 4, 4, 4, 6, 6, 4, 10, 10, 13, 7, 8, 4] False\n",
      "[8, 10, 8, 8, 10, 9, 8, 8, 7, 7, 4, 7, 7, 4, 4, 8] False\n",
      "[8, 13, 6, 6, 11, 4, 9, 11, 7, 11, 4, 4, 10, 7, 8, 10] False\n",
      "[8, 8, 5, 13, 7, 11, 8, 6, 11, 4, 4, 13, 9, 13, 15, 7] False\n",
      "[8, 4, 11, 4, 4, 7, 7, 6, 7, 2, 8, 4, 16, 13, 6, 7] False\n",
      "[8, 6, 4, 4, 11, 4, 7, 4, 7, 8, 4, 11, 11, 13, 4, 13] False\n",
      "[8, 4, 9, 7, 2, 11, 11, 8, 3, 13, 7, 4, 4, 11, 8, 10] False\n",
      "[8, 4, 8, 6, 8, 13, 10, 7, 7, 7, 7, 4, 4, 4, 4, 7] False\n",
      "[8, 4, 8, 10, 11, 4, 4, 7, 4, 8, 8, 8, 13, 4, 7, 4] False\n",
      "[8, 4, 6, 13, 8, 4, 9, 6, 8, 4, 4, 4, 6, 4, 6, 8] False\n",
      "[8, 4, 8, 4, 11, 13, 2, 4, 4, 7, 13, 6, 6, 13, 8, 13] False\n",
      "[8, 6, 7, 4, 6, 11, 4, 7, 12, 8, 13, 13, 7, 11, 7, 10] False\n",
      "[8, 13, 11, 4, 10, 4, 10, 8, 4, 4, 13, 8, 4, 4, 10, 7] False\n",
      "[8, 13, 13, 4, 7, 8, 11, 7, 11, 8, 10, 4, 4, 4, 7, 7] False\n",
      "[8, 4, 6, 8, 8, 7, 8, 7, 4, 6, 10, 7, 11, 11, 7, 4] False\n",
      "[8, 10, 13, 6, 7, 11, 10, 9, 6, 4, 8, 11, 11, 13, 4, 15] False\n",
      "[8, 3, 9, 4, 8, 4, 9, 8, 7, 10, 4, 7, 11, 8, 13, 8] False\n",
      "[8, 7, 20, 4, 6, 7, 4, 13, 7, 13, 4, 4, 13, 4, 15, 6] False\n",
      "[8, 11, 8, 11, 4, 7, 4, 8, 6, 8, 7, 6, 10, 16, 8, 6] False\n",
      "[8, 7, 5, 7, 4, 4, 6, 8, 6, 4, 11, 7, 8, 4, 8, 4] False\n",
      "[8, 8, 7, 4, 11, 9, 10, 11, 11, 8, 7, 8, 8, 8, 6, 4] False\n",
      "[8, 4, 7, 4, 13, 6, 6, 13, 8, 4, 11, 7, 7, 11, 8, 11] False\n",
      "[8, 4, 7, 4, 11, 13, 4, 8, 11, 4, 8, 9, 13, 4, 7, 11] False\n",
      "[8, 7, 6, 7, 8, 11, 8, 4, 8, 17, 8, 8, 4, 8, 7, 7] False\n",
      "[8, 10, 8, 6, 8, 13, 4, 8, 7, 4, 11, 7, 10, 4, 10, 7] False\n",
      "[8, 13, 4, 8, 11, 6, 11, 8, 4, 8, 11, 11, 6, 8, 7, 8] False\n",
      "[8, 4, 10, 10, 6, 6, 11, 13, 10, 4, 7, 4, 13, 11, 6, 8] False\n",
      "[8, 6, 11, 4, 8, 4, 7, 10, 4, 13, 4, 8, 8, 8, 7, 8] False\n",
      "[8, 7, 4, 8, 11, 10, 4, 13, 11, 8, 8, 11, 9, 10, 4, 4] False\n",
      "[8, 11, 4, 7, 13, 10, 4, 7, 8, 4, 13, 10, 6, 4, 4, 7] False\n",
      "[8, 6, 6, 4, 7, 7, 4, 4, 9, 5, 11, 13, 4, 6, 9, 8] False\n",
      "[8, 6, 4, 8, 7, 8, 13, 7, 4, 4, 2, 4, 7, 11, 10, 4] False\n",
      "[8, 2, 7, 10, 11, 7, 4, 13, 8, 10, 7, 13, 8, 8, 16, 10] False\n",
      "[8, 13, 4, 7, 4, 8, 13, 7, 13, 7, 7, 4, 7, 13, 13, 4] False\n",
      "[8, 4, 10, 4, 6, 8, 8, 11, 13, 7, 11, 7, 4, 13, 6, 13] False\n",
      "[8, 9, 6, 4, 7, 8, 8, 4, 13, 7, 11, 15, 7, 15, 13, 11] False\n",
      "[8, 8, 9, 11, 13, 16, 7, 4, 16, 10, 8, 10, 13, 9, 7, 4] False\n",
      "[8, 10, 7, 4, 11, 4, 4, 4, 11, 7, 4, 4, 4, 6, 13, 13] False\n",
      "[8, 4, 6, 7, 6, 13, 8, 7, 4, 11, 8, 11, 7, 13, 4, 13] False\n",
      "[8, 4, 7, 11, 4, 7, 6, 7, 4, 8, 6, 13, 8, 4, 6, 11] False\n",
      "[8, 6, 6, 10, 6, 15, 8, 11, 13, 13, 13, 4, 13, 8, 13, 8] False\n",
      "[8, 8, 13, 7, 7, 4, 4, 13, 13, 8, 7, 13, 4, 11, 7, 11] False\n",
      "[8, 10, 8, 4, 8, 11, 7, 7, 13, 7, 10, 7, 4, 7, 13, 11] False\n",
      "[8, 8, 4, 8, 2, 8, 11, 6, 9, 10, 8, 10, 4, 13, 4, 4] False\n",
      "[8, 4, 8, 15, 4, 9, 4, 7, 10, 4, 8, 13, 7, 4, 11, 8] False\n",
      "[8, 8, 8, 8, 4, 11, 8, 10, 7, 8, 10, 8, 8, 6, 11, 7] False\n",
      "[8, 13, 9, 9, 11, 10, 4, 13, 6, 4, 11, 13, 4, 7, 4, 6] False\n",
      "[8, 8, 4, 2, 12, 8, 7, 4, 8, 7, 4, 4, 4, 11, 8, 13] False\n",
      "[8, 6, 8, 4, 7, 4, 13, 11, 4, 8, 13, 4, 8, 13, 13, 7] False\n",
      "[8, 6, 7, 8, 11, 8, 6, 7, 11, 11, 8, 8, 7, 4, 7, 13] False\n",
      "[8, 13, 13, 11, 11, 7, 13, 13, 8, 4, 6, 10, 7, 4, 6, 13] False\n",
      "[8, 7, 11, 7, 4, 6, 4, 7, 8, 13, 8, 10, 10, 8, 4, 4] False\n",
      "[8, 6, 6, 8, 16, 13, 7, 11, 11, 10, 8, 4, 4, 4, 8, 8] False\n",
      "[8, 8, 8, 9, 11, 4, 6, 7, 4, 8, 7, 4, 6, 6, 4, 11] False\n",
      "[8, 2, 13, 4, 13, 6, 10, 7, 7, 4, 8, 7, 13, 11, 8, 8] False\n",
      "[8, 9, 11, 11, 4, 4, 4, 11, 4, 6, 10, 11, 4, 11, 9, 13] False\n",
      "[8, 4, 11, 10, 4, 6, 8, 8, 13, 4, 7, 11, 6, 4, 7, 4] False\n",
      "[8, 13, 10, 4, 6, 4, 13, 8, 1, 2, 4, 11, 4, 11, 6, 1] False\n",
      "[8, 4, 11, 6, 4, 6, 7, 8, 4, 13, 4, 6, 3, 7, 8, 9] False\n",
      "[8, 6, 4, 10, 7, 6, 4, 11, 13, 7, 6, 4, 6, 6, 8, 8] False\n",
      "[8, 7, 10, 4, 7, 8, 4, 4, 7, 4, 7, 13, 13, 4, 13, 10] False\n",
      "[8, 6, 10, 6, 10, 7, 11, 16, 7, 7, 13, 13, 11, 8, 7, 4] False\n",
      "[8, 4, 6, 10, 7, 10, 13, 6, 8, 4, 4, 11, 13, 10, 8, 6] False\n",
      "[8, 8, 4, 8, 8, 7, 8, 4, 13, 6, 11, 4, 4, 8, 8, 13] False\n",
      "[8, 7, 6, 4, 4, 4, 11, 8, 6, 6, 13, 15, 4, 8, 15, 13] False\n",
      "[8, 8, 6, 6, 13, 8, 4, 6, 4, 6, 5, 4, 4, 13, 4, 13] False\n"
     ]
    }
   ],
   "source": [
    "pair = 0\n",
    "start_size = 8\n",
    "for i in range(100):\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "    a = sample(sizedata[pair], 16, start_size)\n",
    "    print(a, is_subarray(size_index, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "s2s_pair, size_trans = get_trans(pairdata, freqpairs, 'size_index', n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 0.06711409395973156 172\n"
     ]
    }
   ],
   "source": [
    "plf_dict={}\n",
    "# print(size_trans[0])\n",
    "# plf_dict[str(sizedata[0])]=size_trans[0]\n",
    "\n",
    "# print(sizedata[0])\n",
    "minp=100\n",
    "maxp=0\n",
    "ans=0\n",
    "for i in range(1000):\n",
    "    for j in range(i):\n",
    "        if i==j:\n",
    "            continue\n",
    "        minp=min(np.sum(np.abs(sizedata[i]-sizedata[j])),minp)\n",
    "        maxp=max(maxp,np.sum(np.abs(sizedata[i]-sizedata[j])))\n",
    "        if(np.sum(np.square(sizedata[i]-sizedata[j]))<0.001):\n",
    "            ans+=1\n",
    "print(maxp,minp,ans)\n",
    "# for i in range(1000):\n",
    "#     try:\n",
    "#         plf_dict[str(sizedata[i])]\n",
    "#     # if sizedata[i] in plf_dict.keys():\n",
    "#         temp = plf_dict[str(sizedata[i])]\n",
    "#         temp += size_trans[i]\n",
    "#         temp/=2\n",
    "#         plf_dict[str(sizedata[i])]=temp\n",
    "#         print(\"1\\n\")\n",
    "#     except:\n",
    "#         plf_dict[str(sizedata[i])]=size_trans[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 990/8192 [54:18<6:35:01,  3.29s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m size_seq \u001b[39m=\u001b[39m [start_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(size_seq) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     new_size \u001b[39m=\u001b[39m sample(size_data, seq_len, start_size\u001b[39m=\u001b[39;49mstart_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     size_seq \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(new_size[:])\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m inputTensor(np\u001b[39m.\u001b[39marray([[size]]))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m output, hn \u001b[39m=\u001b[39m gru(\u001b[39minput\u001b[39;49m, hn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m output \u001b[39m=\u001b[39m softmax(output)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m p_size \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/root/plf/hotNets-Encore/gru.ipynb 单元格 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m3\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     out_\u001b[39m=\u001b[39mout\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m out \u001b[39m=\u001b[39m o(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m3\u001b[39m\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B166.111.68.231/root/plf/hotNets-Encore/gru.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m out_\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1124\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1125\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1126\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "encore_seq = np.zeros((pairs, 1000))\n",
    "he_seq = np.zeros((pairs, 1000))\n",
    "\n",
    "for pair in tqdm(range(pairs)):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    size_seq = []\n",
    "    while len(size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq.append(size)\n",
    "    size_seq = np.array(size_seq)[0:1000]\n",
    "    he_seq[pair] = size_seq\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(n_size), p=sizedata[pair])\n",
    "        size_seq = [start_size]\n",
    "        while len(size_seq) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq += list(new_size[:])\n",
    "                # start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "            start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        \n",
    "        \n",
    "        size_seq = np.array(size_seq)\n",
    "        values, counts = np.unique(size_seq, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq[:-1] * n_size + size_seq[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            # print(pair, seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "            break\n",
    "\n",
    "    encore_seq[pair] = size_seq[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = pairdata[freqpairs[pair]]['size_index'].values\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        grams[i][pair][values] = counts\n",
    "    grams[i] /= grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "he_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    he_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = he_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        he_grams[i][pair][values] = counts\n",
    "    he_grams[i] /= he_grams[i].sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "encore_grams = {}\n",
    "for i in [2, 3, 4]:\n",
    "    encore_grams[i] = np.zeros((pairs, n_size ** i))\n",
    "    for pair in tqdm(range(pairs)):\n",
    "        sizeindex = encore_seq[pair].astype(int)\n",
    "        l = len(sizeindex) - i + 1\n",
    "        feature = np.zeros(l, dtype=int)\n",
    "        for j in range(i):\n",
    "            feature += sizeindex[j:j+l] * n_size ** (i - j - 1)\n",
    "        values, counts = np.unique(feature, return_counts=True)\n",
    "        encore_grams[i][pair][values] = counts\n",
    "    encore_grams[i] /= encore_grams[i].sum(axis=1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_jsds, encore_jsds = {}, {}\n",
    "for i in range(2, 5):\n",
    "    he_jsds[i] = []    \n",
    "    encore_jsds[i] = []    \n",
    "    for pair in range(pairs):\n",
    "        he_jsds[i].append(JSD(grams[i][pair], he_grams[i][pair]))\n",
    "        encore_jsds[i].append(JSD(grams[i][pair], encore_grams[i][pair]))\n",
    "    he_jsds[i] = np.array(he_jsds[i])\n",
    "    encore_jsds[i] = np.array(encore_jsds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(2, 5):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.subplots_adjust(left=0.18, top=0.95, bottom=0.24, right=0.98)\n",
    "    ax = plt.subplot(111)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    values, bins = np.histogram(encore_jsds[i], bins=np.arange(0, np.max(encore_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='CornFlowerBlue', label='Encore-Sequential')\n",
    "    values, bins = np.histogram(he_jsds[i], bins=np.arange(0, np.max(he_jsds[i]) + 0.01, 0.01))\n",
    "    cdf = np.cumsum(values) / np.sum(values)\n",
    "    plt.plot(bins[:-1], cdf, linewidth=2, color='IndianRed', label='Common Practice')\n",
    "    plt.ylim(0, 1.05)\n",
    "    # plt.legend(fontsize=20, frameon=False, loc=(0.45, 0.2))\n",
    "    plt.ylabel('CDF', fontsize=20)\n",
    "    plt.xlabel('JSD', fontsize=20)\n",
    "    plt.grid(linestyle='-.')\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    if i == 2:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.125, 0.84, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    elif i == 3:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.22, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    else:\n",
    "        bbox_props = dict(boxstyle=\"larrow\", fc=\"none\", ec=\"red\", lw=2)\n",
    "        t = ax.text(0.3, 0.8, \"Better\", ha=\"center\", va=\"center\", rotation=0,\n",
    "                    size=18,\n",
    "                    bbox=bbox_props)\n",
    "    plt.legend(fontsize=20, frameon=False, loc=(0.185, -0.025), handletextpad=0.5)\n",
    "\n",
    "    plt.savefig('figure/{i}-gram-jsd.pdf'.format(i=i), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_jsds, he_jsds,min_jsds = [], [],[]\n",
    "for pair in range(500):\n",
    "    size_data = sizedata[pair]\n",
    "    size_index = np.concatenate((pairdata[freqpairs[pair]].size_index.values, pairdata[freqpairs[pair]].size_index.values[0:1]))\n",
    "\n",
    "    for seed in range(10):\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = [start_size]\n",
    "        while len(size_seq_gen) < 1000:\n",
    "            new_size = sample(size_data, seq_len, start_size=start_size)\n",
    "            # if set(new_size).issubset(np.unique(pairdata[freqpairs[pair]].size_index.values)):\n",
    "            size_seq_gen += list(new_size[1:])\n",
    "            start_size = new_size[-1]\n",
    "                # if seed > 10:\n",
    "                #     start_size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        size_seq_gen = np.array(size_seq_gen)\n",
    "        values, counts = np.unique(size_seq_gen, return_counts=True)\n",
    "        new_size = np.zeros(n_size, dtype=float)\n",
    "        new_size[values] = counts\n",
    "        new_size /= new_size.sum()\n",
    "\n",
    "        rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "        values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "        rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "        rnn_s2s_pair[values] = counts\n",
    "        rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "        \n",
    "        # print(seed, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "        if JSD(new_size, sizedata[pair]) < 0.005:\n",
    "            break\n",
    "\n",
    "    rnn_s2s_pair = [size_seq_gen[:-1] * n_size + size_seq_gen[1:]]  \n",
    "    values, counts = np.unique(rnn_s2s_pair, return_counts=True)\n",
    "    rnn_s2s_pair = np.zeros(n_size ** 2, dtype=float)\n",
    "    rnn_s2s_pair[values] = counts\n",
    "    rnn_s2s_pair /= rnn_s2s_pair.sum()\n",
    "\n",
    "    he_size_seq = []\n",
    "    while len(he_size_seq) < 1000:\n",
    "        size = np.random.choice(np.arange(30), p=sizedata[pair])\n",
    "        he_size_seq.append(size)\n",
    "    he_size_seq = np.array(he_size_seq)\n",
    "\n",
    "    he_s2s_pair = [he_size_seq[:-1] * n_size + he_size_seq[1:]]  \n",
    "    values, counts = np.unique(he_s2s_pair, return_counts=True)\n",
    "    he_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    he_s2s_pair[values] = counts\n",
    "    he_s2s_pair /= he_s2s_pair.sum()\n",
    "    \n",
    "    min_size_seq = []\n",
    "    min_size_seq.append(np.random.choice(n_size, p=size_data))\n",
    "    while len(min_size_seq) < 1000:\n",
    "        min_size_seq.append(np.random.choice(n_size, p=size_trans[pair][min_size_seq[-1]]))\n",
    "    min_size_seq = np.array(min_size_seq)\n",
    "        \n",
    "    min_s2s_pair = [min_size_seq[:-1] * n_size + min_size_seq[1:]]  \n",
    "    values, counts = np.unique(min_s2s_pair, return_counts=True)\n",
    "    min_s2s_pair = np.zeros(n_size * n_size, dtype=float)\n",
    "    min_s2s_pair[values] = counts\n",
    "    min_s2s_pair /= min_s2s_pair.sum()\n",
    "\n",
    "    print(pair, JSD(new_size, sizedata[pair]), JSD(rnn_s2s_pair, s2s_pair[pair]), JSD(he_s2s_pair, s2s_pair[pair]))\n",
    "    rnn_jsds.append(JSD(rnn_s2s_pair, s2s_pair[pair]))\n",
    "    min_jsds.append(JSD(min_s2s_pair, s2s_pair[pair]))\n",
    "    he_jsds.append(JSD(he_s2s_pair, s2s_pair[pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "values, bins = np.histogram(rnn_jsds, bins=np.arange(0, np.max(rnn_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(he_jsds, bins=np.arange(0, np.max(he_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "values, bins = np.histogram(min_jsds, bins=np.arange(0, np.max(min_jsds) + 0.01, 0.01))\n",
    "cdf = np.cumsum(values) / np.sum(values)\n",
    "plt.plot(bins[1:], cdf)\n",
    "\n",
    "plt.ylim(0, 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 99]:\n",
    "    print(i, np.percentile(rnn_jsds, i), np.percentile(he_jsds, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(gru, 'models/gru-0504.pth')\n",
    "# torch.save(s2h, 'models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizeDecoder(torch.nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dims, latent_dim):\n",
    "        super(SizeDecoder, self).__init__()\n",
    "        self.decoder = torch.nn.ModuleList()\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            self.decoder.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(in_dim, out_features=h_dim,),\n",
    "                    nn.ReLU())\n",
    "            )\n",
    "            in_dim = h_dim\n",
    "        self.output = nn.Linear(hidden_dims[-1], output_dim)\n",
    "    \n",
    "    def forward(self, x: Tensor) -> List[Tensor]:\n",
    "        for module in self.decoder:\n",
    "            x = module(x)\n",
    "        result = self.output(x)\n",
    "        result = F.softmax(result, dim=1)\n",
    "        return result\n",
    "    \n",
    "decoder = torch.load('models/size-decoder-0425.pth')\n",
    "gru = torch.load('models/gru-0504.pth')\n",
    "s2h = torch.load('models/s2h-0504.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from tqdm import tqdm\n",
    "def JSD(p, q):\n",
    "    p = list(p)\n",
    "    q = list(q)\n",
    "    pq_max_len = max(len(p), len(q))\n",
    "    p += [0.0] * (pq_max_len - len(p))\n",
    "    q += [0.0] * (pq_max_len - len(q))\n",
    "    assert (len(p) == len(q))\n",
    "    m = np.sum([p, q], axis=0) / 2\n",
    "    return 0.5 * entropy(p, m) + 0.5 * entropy(q, m)\n",
    "\n",
    "def sample_noisy_dataset(n, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = []\n",
    "    for i in tqdm(range(n)):\n",
    "        latent_dim = 32\n",
    "        z = torch.randn((1, latent_dim)).to(device)\n",
    "        size = decoder(z)\n",
    "        size = size.squeeze().detach().to('cpu').numpy()\n",
    "        size[size < 1e-3] = 0\n",
    "        size /= size.sum()\n",
    "\n",
    "        dis = []\n",
    "        for j in range(1000):\n",
    "            loss = JSD(size, sizedata[j])\n",
    "            dis.append(loss)\n",
    "\n",
    "        pair = np.argmin(dis)\n",
    "        ran_index = np.random.randint(len(seq_set[pair]))\n",
    "        dataset.append([seq_set[pair][ran_index], size, target_set[pair][ran_index]])\n",
    "        \n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
